Kubernetes Cookbook:

Deploymnet and Service from CLI:

$ kubectl run ghost --image=ghost:0.9
$ kubectl expose deployments ghost --port=2368 --type=NodePort


Get multiple Kubernetes resources

$ kubectl get pods,rs,deployments


Installing kubeadm:
We need kubeadm installed on all the servers that will be part of our Kubernetes cluster.

If using Ubuntu, on each of the hosts run the following commands as root to setup Kubernetes package repository

# apt-get update && apt-get install -y apt-transport-https

# curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -

# cat <<EOF >/etc/apt/sources.list.d/kubernetes.list
  deb http://apt.kubernetes.io/ kubernetes-xenial main
  EOF

# apt-get update

Now we can install Docker, kubeadm, kubectl, kubelet, and kubernetes-cni

# apt-get install -y docker.io
# apt-get install -y kubelet kubeadm kubectl kubernetes-cni

Bootstrapping a Kubernetes Cluster using kubeadm

On Master Node:
# kubeadm init
...
...

On other nodes:
# kubeadm join --token <token>

On Master Node:
$ kubectl get nodes
Here we will see our nodes join the cluster

Final step is to create a network that satisfies Kubernetes Networking Requirements - single IP per Pod
We can use any of the network add-ons, however Weave Net can be installed on Kubernetes v1.6.0 and above with a single command like below.

$ export kubever=$(kubectl version | base64 | tr -d '\n')
$ kubectl apply -f "https://cloud.weave.works/k8s/net?k8s-version=$kubever"

This command will create daemonset running on all nodes in the cluster.
Pods of the daemonset use the host network and a CNI plug-in to configure the local node network.

Our nodes will enter READY state once the network is in place.


Writing systemd Unit File to Run Kubernetes Components:

If we look closely at the kubeadm configuration,
we will see that kubelet running on every node in our cluster, including the master node is managed by systemd

Log in to any of the nodes in the cluster we built using kubeadm

# systemctl status kubelet
kubelet.service - kubelet: The Kubernetes Node Agent
 Loaded: loaded (/lib/systemd/system/kubelet.service; enabled; vendor present: enabled)
Drop-In: /etc/systemd/system/kubelet.service.d
         \__10-kubeadm.conf
...
...

This gives us a link to the systemd unit file: /lib/systemd/system/kubelet.service
And its configuration in /etc/systemd/system/kubelet.service.d/10-kubeadm.conf

The unit file points to kubelet binary installed at /usr/bin/kubelet
The configuration file has information on how the kubelet binary should be started

All the options specified in the configuration file, such as --kubeconfig, defined by environment variable $KUBELET_CONFIG_ARGS,
are startup options of the kubelet binary

Kubelet Reference:
https://kubernetes.io/docs/reference/command-line-tools-reference/kubelet/

--pod-manifest-path=/etc/kubernetes/manifests path defined by environment variable $KUBELET_SYSTEM_PODS_ARG
is the path where kubelet will look for manifests that it will automatically start.

# ls /etc/kubernetes/manifests
etcd.yaml, kube-apiserver.yaml, kube-controller-manager.yaml, kube-scheduler.yaml


Using Kubernetes Client:

Listing Resources:

$ kubectl get pods

$ kubectl get deployments,services

$ kubectl get deployment my-deployment

$ kubectl get all

Resource Short Names:
configmaps : cm
daemonsets : ds
deployments : deploy
endpoints : ep
events : ev
horizontalpodautoscaler : hpa
ingresses : ing
namespaces : ns
nodes : no
pods : po
persistentvolumes : pv
persistentvolumeclaims : pvc
replicasets : rs
replicationcontrollers : rc
resourcequotas : quota
serviceaccounts : sa
services : svc

Deleting Resources:

Delete all resources in a namespace:
$ kubectl get ns
...
my-app   Active   20m

$ kubectl delete ns my-app
namespace "my-app" deleted

Delete resources labeled with app=my-app
$ kubectl delete svc,deploy -l app=my-app

Force delete a pod:
$ kubectl delete pod hangingpod --grace-period=0 --force

Delete all pods in a namespace
$ kubectl delete pods --all --namespace test

Watch changes to Kubernetes objects in an interactive manner:
$ kubectl get pods --watch

alternatively we can use the watch command like below..
$ watch kubectl get pods

Editing Resources with kubectl
$ kubectl run nginx --image=nginx
$ kubectl edit deploy/nginx
...
deployment "nginx" edited
NOTE: NOT ALL CHANGES TRIGGER A DEPLOYMENT

Explain resources and Fields:
$ kubectl explain svc

$ kubectl explain svc.spec.externalIPs

KUBECTL EXPLAIN: https://blog.heptio.com/kubectl-explain-heptioprotip-ee883992a243

HEPTIO PROTIP: https://blog.heptio.com/tagged/heptioprotip


Creating and Modifying Fundamental Workloads:

Creating a Deployment Using kubectl run:
$ kubectl run ghost --image=ghost:0.9

$ kubectl get deploy/ghost

kubectl run command takes a number of argumensts to configure additional parameters of the deployment.

--env Set environment variables
--port Define container ports
--command Define a command to run using
--expose Automatically create an associated service
--replicas Define the number of pods

$ kubectl run ghost --image=ghost:0.9 --port=2368 --expose

$ kubectl run mysql --image=mysql:5.5 --env=MYSQL_ROOT_PASSWORD=root

$ kubectl run myshell --image=busybox --comman -- sh -c "sleep 3600"

$ kubectl run --help

Creating Objects from Manifest files:

$ cat myns.yaml
apiVersion: v1
kind: namespace
metadata:
  name: myns

$ kubectl create -f myns.yaml

We can also point kubectl create to a URL instead of a file.

$ kubectl create -f https://path/to/manifest/file


Pod Manifest:
Pod is an /api/v1 obect, Pod manifest contains the following fields

> apiVersion : Specifies the API version
> kind : indicates the type of the object
> metadat : provides some metadata about the object
> spec : provides the object specification

A Pod can contain multiple containers as in the below example.

apiVersion: v1
kind: Pod
metadata:
  name: oreilly
spec:
  containers:
  - name: oreilly
    image: nginx
  - name: safari
    image: redis


Deployment from a Manifest file:

$ cat fancyapp.yaml
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: fancyapp
spec:
  replicas: 5
  template:
    metadata:
      labels:
        app: fancyapp
        env: development
    spec:
      containers:
      - name: sise
        image: mhausenblas/simpleservice:0.5.0
        ports:
        - containerPort: 9876
        env:
        - name: SIMPLE_SERVICE_VERSION
          value: "0.9"

$ kubectl create -f fancyapp.yaml

$ kubectl get deploy

$ kubectl get rs

$ kubectl get po



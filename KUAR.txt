KUAR

Pushing Image to Google Container Registry

Tag kuard image as below
$ docker tag kuard-amd64:1 gcr.io/kuard-demo/kuard-amd64:1

Push the kuard image
$ docker push gcr.io/kuard-demo/kuard-amd64:1


Running Containers with Docker

$ docker run -d --name kuard --publish 8080:8080 gcr.io/kuard-demo/kuard-amd64:1

Exploring the kuard application:
Point your browser at http://localhost:8080 (or) $ curl http://localhost:8080

Docker provides ability to limit resources by exposing underlying cgroup

Stop and remove kuard container
$ docker stop kuard
$ docker rm kuard

Limiting Memory Resources
Use --memory and --memory-swap flags with docker run command to specify 200 MB of memory and 1 GB of swap space.

$ docker run -d --name kuard --publish 8080:8080 --memory 200m --memory-swap 1G gcr.io/kuard-demo/kuard-amd64:1

Limiting CPU Resources
Use --cpu-shares flag with docker run command to restrict CPU utilization

$ docker run -d --name kuard --publish 8080:8080 --memory 200m --memory-swap 1G --cpu-shares 1024 gcr.io/kuard-demo/kuard-amd64:1

Cleanup Container Images

$ docker images 

We can delete container images with docker rmi command, by specifying either the image tag or image-ID

$ docker rmi <tag-name>
$ docker rmi gcr.io/kuard-demo/kuard-amd64:1

or

$ docker rmi <image-id>


Installing Kubernetes on GCP

Set a default zone:
$ gcloud config set compute/zone us-west1-a

Create Kubernetes Cluster:
$ gcloud container clusters create kuar-cluster

Get credentials for the cluster:
$ gcloud auth application-default login

Kubernetes Client:
kubectl: a command line tool for interacting with Kubernetes API
Used to manage most Kubernetes objects such as pods, ReplicaSets, and Services
kubectl can also be used to explore and verify the overall health of the cluster

Checking cluster version:

$ kubectl version
> This command will display version of the local kubectl tool, as well as the version of Kubernetes API server

Get simple diagnostic for the cluster:

$ kubectl get componentstatuses
> This command displays health status of components that make up the kubernetes cluster

controller-manager: is responsible for running various controllers that regulate behavior in the cluster
scheduler is responsible for placing different pods on to different nodes in the cluster
etcd server is the storage for the cluster where all of the API objects are stored

Listing Kubernetes Worker Nodes:

$ kubectl get nodes
NAME         STATUS         AGE   VERSION
kubernetes   Ready,master   45d   v1.7.6
node-1       Ready          45d   v1.7.6
node-2       Ready          45d   v1.7.6
node-3       Ready          45d   v1.7.6

Kubernetes nodes are separated in to master nodes that contain containers like the API server, scheduler, etc
and worker nodes where our application containers will run.

Kubernetes won't generally schedule work on to master node,
to ensure that user workloads does not harm the overall operation of the cluster

We can use kubectl describe command to get more information about a specific node

$ kubectl describe nodes node-1

This command outputs information about operation of the node, capacity of the machine, software running on the node,
including versions of docker, kubernetes and Linux kernel, information about pods that are currently running on this node

Cluster Components
==================
Many of the components that make up the cluster are actually deployed using Kubernetes itself.
All of these components run in the kube-system namespace

Kubernetes Proxy:
-----------------
Kubernetes proxy is responsible for routing network traffic to load-balanced services in the cluster
Proxy must be present on every node in the cluster to be able to perform traffic routing
If your cluster runs the Kubernetes Proxy as a DaemonSet, we can see the proxies by running the below command

$ kubectl get daemonSets --namespace=kube-system kube-proxy
NAME        DESIRED   CURRENT   READY   NODE-SELECTOR   AGE
kube-proxy  4         4         4       <none>          45d

Kubernetes DNS:
---------------
Kubernetes DNS server provides naming and discovery for the services that are defined in the cluster.
Kubernetes DNS server runs as a replicated service on the cluster
Depending on the size of your cluster, you might see one or more DNS servers running in your cluster
Kubernetes DNS service is usually run as a Kubernetes deployment which manages these replicas

$ kubectl get deployments --namespace=kube-system kube-dns
NAME        DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE
kube-dns    1         1         1            1           45d

There is also usually a Kubernetes service that performs load-balancing for the DNS server

$ kubectl get services --namespace=kube-system kube-dns
NAME      CLUSTER-IP  EXTERNAL-IP  PORT            AGE
kube-dns  10.96.0.10  <none>       53/UDP, 53/TCP  45d

This shows that the DNS service for the cluster has the address 10.96.0.10,
If we log in to a container in the cluster, we will see that this has been populated in to the /etc/resolv.conf for the container

Kubernetes UI:
--------------
UI is run as a single replica, UI is managed by a Kubernetes deployment for reliability and upgrades
We can see this UI server running using the below command

$ kubectl get deployments --namespace=kube-system kubernetes-dashboard
NAME                    DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE
kubernetes-dashboard    1         1         1            1           45d

Dashboard also has a service that performs load balancing for the dashboard

$ kubectl get service --namespace=kube-system kubernetes-dashboard
NAME                  CLUSTER-IP     EXTERNAL-IP  PORT            AGE
kubernetes-dashboard  10.99.104.174  <none>       53/UDP, 53/TCP  45d

We can use kubectl proxy to access the dashboard

$ kubectl proxy
This command starts up a server running on localhost:8001 

A Namespace in Kubernetes is an entity for organizing Kubernetes resources.
We can think of it like a folder in a filesystem

Common Kubectl Commands
=======================
kubectl commands that apply to all kubernetes objects

Namespaces:
-----------
Kubernetes uses namespaces to organize objects in the cluster
We can think of each namespace as a folder that holds a set of objects
By default kubectl interacts with the default namespace
If we want to use a different namespace, we can use --namespace flag to specify the same

$ kubectl get deployments --namespace=mystuff
This command will get all deployments in mystuff namespace

Contexts:
---------
We can change the default namespace in kubectl configuration file, usually located at $HOME/.kube/config
This configuration file also stores how to both find and authenticate to our cluster

We can create a context with a different default namespace for our kubectl commands by running the below command
$ kubectl config set-context my-context --namespace=mystuff

To use the above newly created context, run the below command
$ kubectl config use-context my-context

Contexts can also be used to manage different clusters or different users for authenticating to those clusters
using --users or --clusters flags with the set-context command

Viewing Kubernetes Objects:
---------------------------
Everything contained in kubernetes is represented by a RESTful resource,
we refer to these resources as Kubernetes objects

Each Kubernetes object exists at a unique HTTP path,
https://your-k8s.com/api/v1/namespaces/default/pods/my-pod is the representation of a pod named "my-pod" in default namespace

kubectl command makes HTTP requests to these URLs to access the Kubernetes objects that resides at these paths

$ kubectl get <resource-name>
This command will get a listing of all resources in the current namespace

$ kubectl get <resource-name> <object-name>
This command will get the specific resource specified by <object-name>

Ex:
Get pods in all namespaces
$ kubectl get pods --all-namespaces
$ kubectl get pods --namespace=my-namespace -o=wide
$ kubectl get pods -o=yaml
$ kubectl get pods -l environment=production,tier=frontend
$ kubectl get pods -l 'environment in (production, qa),tier notin (backend)'
$ kubectl get deployments
$ kubectl get deployments my-deployment
$ kubectl get replicasets

By default, kubectl uses a human-readable printer for viewing the responses from the API server,
we can use -o wide flag to get slightly more information

If we want to view the complete object, we can use -o json or -o yaml flags,
to view the objects as raw JSON or YAML respectively

If we specify --no-header flag, kubectl will skip the headers at the top of the human-readable table,
this output can be piped to other linux commands like awk for processing

kubectl uses JSONPath query language to select fields in the returned object

$ kubectl get pods my-pod -o jsonpath --template={.status.podIP}
This command will extract and print the IP address of my-pod

$ kubectl get pods -o=jsonpath="{.items[*].spec.containers[*].image}"

More detailed information about a particular object can be obtained using kubectl describe command
$ kubectl describe <resource-name> <object-name>

We use YAML or JSON files to create, update, or delete objects on the Kubernetes cluster

Assuming that we have an object specification stored in obj.yaml,
we can use kubectl to create the object as below

$ kubectl apply -f obj.yaml

Similarly, we can make changes to the object specification and run apply command again to update the object in Kubernetes

$ kubectl apply -f obj.yaml

Interactive Editing Of Kubernetes Objects:
------------------------------------------

$ kubectl edit <resource-name> <object-name>
This command will download the latest object state, and launch an editor to edit the object definition

When we want to delete an object

$ kubectl delete -f obj.yaml

or

$ kubectl delete <resource-name> <object-name>
$ kubectl delete pod my-pod
$ kubectl delete pods -l name=myPod

Labeling and Annotating Objects:
--------------------------------
We can update labels and annotations on any Kubernetes object using annotate and label commands

$ kubectl label pods my-pod color=red
This command adds the color=red label to pod named my-pod

By default, label and annotate commands will not allow us to overwrite an existing label,
we have to specify --overwrite flag to be able to overwrite existing labels or annotations
$ kubectl label pods my-pod color=blue --overwrite

Removing a label can be done by using <label-name>- syntax
$ kubectl label pods my-pod color-


Debugging Commands:
-------------------
See logs of a running container

$ kubectl logs <pod-name>

If we have multiple containers in our pod, we can choose the container to view using -c flag

By default, kubectl logs command lists the current logs and exits,
-f flang can be specified to continuously stream logs

We can also use exec command to execute a command in a running container

$ kubectl exec -it <pod-name -- bash

We can copy files to and from a container using cp command

$ kubectl cp <pod-name>:/path/to/remote/file /path/to/local/file

$ kubectl cp /path/to/local/file <pod-name>:/path/to/remote/file

Pods in Kubernetes:
-------------------
Pod represents a collection of application containers and volumes running in the same execution environment.
Pods are the smallest deployable artifacts in a Kubernetes cluster
All the containers in a Pod always land on the same machine

Each container within a Pod runs in its own cgroup
Containers in a Pod share a number of Linux namespaces

Applications running in the same Pod:
Share the same IP address and port space (network namespace)
Have the same hostname (UTS namespace)
Can communicate using native interprocess communication channels over System V IPC or POSIX message queues (IPC namespace)

Applications in different Pods are isolated from each other;
they have different IP addresses, different hostnames and more

Will these containers work correctly if they land on different machines ?
=========================================================================
If the answer is "no", a Pod is the correct grouping for the containers.
If the answer is "yes", multiple Pods is probably the correct solution.

The Pod Manifest:
=================
Pods are described in a Pod manifest.
The Pod manifest is just a text-file representation of the Kubernetes API object.

The Kubernetes API server accepts and processes Pod manifest before storing them in persistent storage (etcd)
The Scheduler uses Kubernetes API to find Pods that haven't been scheduled to a node.
The Scheduler then places the Pods on to nodes depending on resources and other constraints expressed in the Pod manifest.

Scheduling multiple replicas of the same application on to the same machine is bad for reliability,
since the machine is a single failure domain

Creating a Pod:
---------------

Simplest way to create a Pod is via the imperative kubectl run command

$ kubectl run kuard --image=gcr.io/kuar-demo/kuard-amd64:1

$ kubectl get pods

This manner of creating a Pod actually creates it via Deployment and ReplicaSet object

$ kubectl delete deployments/kuard

Creating a Pod Manifest:
------------------------
Pod manifests include a couple of key fields and attributes:

A metadata section for describing the Pod and its labels
A spec section for describing the list of containers that will run in the Pod
Spec section also describes volumes and ports

kuard-pod.yaml
--------------
apiVersion: v1
kind: Pod
metadata:
  name: kuard
spec:
  containers:
    - image: gcr.io/kuar-demo/kuard-amd64:1
	  name: kuard
	  ports:
	    - containerPort: 8080
		  name: http
		  protocol: TCP


$ kubectl apply -f kuard-pod.yaml

Pod manifest will be submitted to the Kubernetes API server.
Kubernetes system will then schedule that Pod to run on a healthy node in the cluster
Pod will be monitored by the kubelet daemon process on the node.

Listing Pods:
-------------

$ kubectl get pods
NAME   READY   STATUS   RESTARTS AGE
kuard  1/1     Running  0        44s

If we ran the command immediately after the Pod was created, we might see:

$ kubectl get pods
NAME   READY   STATUS   RESTARTS AGE
kuard  0/1     Pending  0        44s

Pending state here indicates that the Pod has been submitted but hasn't been scheduled yet.

NOTE:
Adding -O wide to any kubectl command will print out slightly more information
Adding -O json or -O yaml will print out the complete objects in JSON or YAML

Pod Details:
------------
Kubernetes maintains numerous events about Pods that are present in the event stream,
not attached to the Pod object.

$ kubectl describe pods kuard

Describe command has the following
1. Basic information about the Pod
2. Information about the containers running in the Pod
3. Events related to the Pod, such as when it was scheduled,
   when its image was pulled and when it had to be restarted because of failing health checks
   
Deleting a Pod:
---------------

$ kubectl delete pods/kuard

$ kubectl delete -f kuard-pod.yaml

NOTE:
When a Pod is deleted, it is not immediately killed.
All Pods have a termination grace period, by default this is 30 seconds.
When a Pod is transitioned to Terminating it no longer receives new requests.

In serving scenario, the grace period is important for reliability as it allows the Pod
to finish any active requests that it may be in the middle of processing before it terminated

PersistentVolumes should be used if we want to persist data across multiple instances of a Pod

Accessing Our Pod:
==================

Port Forwarding
---------------
$ kubectl port-forward kuard 8080:8080

This command creates a secure tunnel from our local machine, through the Kubernetes master,
to the instance of the Pod running on one of the worker nodes

When port-forwarding is active, we can access the pod on http://localhost:8080

Accessing Logs
--------------
$ kubectl logs kuard

This command downloads the current logs from the running instance
-f flag will continuously stream logs
--previous flag will get logs from a previous instance of the container

NOTE:
Its generally useful to use a log aggregation service,
Log aggregation services provide storing, and rich log searching and filtering capabilities
Log aggregation services also provide the ability to aggregate logs from multiple Pods in to one view

Running commands in our Container with exec
-------------------------------------------
$ kubectl exec kuard date

-it flag will get us an interactive session

$ kubectl exec -it kuard ash

Copying files to and from containers
------------------------------------
$ kubectl cp <pod-name>:/path/to/remote/file /path/to/local/file

$ kubectl cp <pod-name>:/captures/capture3.txt ./capture3.txt

Copy from local machine in to a container

$ kubectl cp $HOME/config.txt <pod-name>:/config.txt

Generally speaking, copying files in to a container is an antipattern

Health Checks
=============
Kubernetes ensures that the main process of our application is always running.
If it isn't, then Kubernetes restarts it

Liveness Probe:
---------------
Liveness health checks run application specific logic to verify that the application is functioning properly.
Liveness probes are defined per container, i.e. each container inside a Pod is health checked separately
Liveness probes have to be defined in our Pod manifest.

kuard-pod-health.yaml
---------------------
apiVersion: v1
kind: Pod
metadata:
  name: kuard
spec:
  containers:
    - image: gcr.io/kuar-demo/kuard-amd64:1
	  name: kuard
	  livenessProbe:
	    httpGet:
		  path: /healthy
		  port: 8080
		initialDelaySeconds: 5
		timeoutSeconds: 1
		periodSeconds: 10
		failureThreshold: 3
	  ports:
	    - containerPort: 8080
		  name: http
		  protocol: TCP

Here we have added a liveness probe to our kuard container,
which runs an HTTP get request against the /healthy path on our container

i.e. an httpGet probe to perform an HTTP GET request against the /healthy endpoint on port 8080 of kuard container
The probe sets an initialDelaySeconds of 5, and thus will not be called until five seconds after all the containers in the Pod are created.

Probe must respond within the specified timeoutSeconds
HTTP status code must be between 200 to 400 to be considered successful
Probe will be called every x seconds specified by periodSeconds

If more than three probes fail, the container will fail and restart

>>Create a Pod using the above manifest file.
$ kubectl apply -f kuard-pod-health.yaml

>>Port-forward to kuard Pod
$ kubectl port-forward kuard 8080:8080

>>Point your browser to http://localhost:8080

>>Click the "Liveness Probe" tab.

>>If we click the "fail" link on that page, kuard will start to fail health checks

>>After some time, Kubernetes will restart the container

Details of the restart can be found with kubectl describe pods command

$ kubectl describe pods kuard
Events section in this command's output will have details about restart


Readiness Probe:
----------------
Readiness describes when a container is ready to serve user requests.
Containers that fail readiness checks are removed from service load balancers.
Readiness probes are configured similar to Liveness probes

Combining Readiness and Liveness probes helps ensure that only healthy containers are running within the cluster

Other Types of Health Checks
----------------------------
>>TCP Socket:
=============
Kubernetes supports tcpSocket health checks that open a TCP socket,
If the connection is successful, the probe succeeds
This style of probe is useful for non-HTTP applications; example database or other non-HTTP-based APIs

>>Exec Probes:
==============
Kubernetes exec probes execute a script or program in the context of the container.
if the script returns a zero exit code, the probe succeeds; otherwise it fails.
exec scripts are often useful for custom application validation logic that doesn't fit neatly in to HTTP call

Resource Management: (REQUESTS & LIMITS)
========================================
Kubernetes allows users to specify two different resource metrics.
>>Resource requests specify the minimum amount of a resource required to run the application.
>>Resource limits specify the maximum amount of a resource that an application can consume.

Minimum Required Resources:
---------------------------
Pod requests the resources required to run its containers,
Kubernetes guarantees that these resources are available to the Pod

Most commonly requested resources are CPU and Memory,
Kubernetes has other resource types such as GPUs and more.

To request that the kuard container lands on a machine with
half a CPU free and gets 128 MB of memory allocated to it, we define the Pod as shown below

kuard-pod-resourcerequest.yaml
------------------------------
apiVersion: v1
king: Pod
metadata:
  name: kuard
spec:
  containers:
    - image: gcr.io/kuar-demo/kuard-amd64:1
	  name: kuard
	  resources:
	    requests:
		  cpu: "500m"
		  memory: "128Mi"
	  ports:
	    - containerPort: 8080
		  name: http
		  protocol: TCP

NOTE:
Resources are requested per container, not per Pod.
Total resources requested by a Pod is the sum of all resources requested by all containers in that Pod.
This is to respect the fact that different containers have different CPU requirements.

Request specifies a MINIMUM resources required,
It does not specify a MAXIMUM cap on the resources a Pod may use.

SCENARIO:
---------
Our CODE attempts to use all available CPU cores.
Our Pod requests 0.5 CPU cores.
Kubernetes schedules our Pod on a node with total 2 CPU cores.

As long as our Pod is the only Pod scheduled on the node, it will consume all 2 CPU cores available.
If a second Pod with the same request of 0.5 CPU lands on the node, then each Pod will receive 1 CPU cores.
If a third identical Pod lands on the same node, each Pod will receive 0.66 CPU cores.
If a fourth identical Pod lands on the same node, each Pod will receive 0.5 CPU cores it requested and the node will be at capacity.

CPU requests are implemented using cpu-shares functionality in Linux kernel

NOTE:
-----
Memory requests are handled similar to CPU requests.
If a container is using more memory than its request, then OS can't just remove the allocated memory from the process,
When the system runs out of memory, KUBELET TERMINATES containers whose MEMORY USAGE IS GREATER THAN THEIR REQUESTED memory.
These containers are automatically restarted, but with less available memory on the machine for the container to consume.

Capping Resource Usage with Limits:
===================================
We can also set a maximum on  a Pod's resource usage via resource limits.

kuard-pod-requests-limits.yaml
------------------------------
apiVersion: v1
king: Pod
metadata:
  name: kuard
spec:
  containers:
    - image: gcr.io/kuar-demo/kuard-amd64:1
	  name: kuard
	  resources:
	    requests:
		  cpu: "500m"
		  memory: "128Mi"
		limits:
		  cpu: "1000m"
		  memory: "256mi"
	  ports:
	    - containerPort: 8080
		  name: http
		  protocol: TCP

When we specify LIMITS on a container, the kernel is configured to ensure that consumption can not exceed the LIMITS.

A container with a CPU limit of 0.5 cores will only ever get 0.5 cores, even if the CPU is otherwise idle.
A container with a memory limit of 256 MB will not be allowed additional memory (e.g., malloc will fail)

Persisting Data with Volumes
============================
All data in the container's file system is deleted when a Pod is deleted or when a container is restarted.

spec.volumes section of the manifest defines all the volumes that may be accessed by containers in the Pod.
volumeMounts array in the container definition defines volumes that are mounted into a particular container,
and the path where each volume should be mounted.

Two different containers in a Pod can mount the same volume at different mount paths.

kuard-pod-vol.yaml
------------------
apiVersion: v1
king: Pod
metadata:
  name: kuard
spec:
  volumes:
    - name: "kuard-data"
	  hostPath:
	    path: "/var/lib/kuard"
  containers:
    - image: gcr.io/kuar-demo/kuard-amd64:1
	  name: kuard
	  volumeMounts:
	    - mountPath: "/data"
		  name: "kuard-data"
	  ports:
	    - containerPort: 8080
		  name: http
		  protocol: TCP

Different Ways of Using Vilumes with Pods
-----------------------------------------

Communication / Synchronization:
--------------------------------
Two containers in a Pod use a shared volume to serve a site while keeping it synchronized with a remote Git repo.
Pod should use an emptyDir volume to acheive this, emptyDir volume is scoped to the Pods lifespan and can be shared between two containers.

Cache:
------
Application may use a volume that is valuable for performance, but not required for correct operation of the application.
i.e. application keeps pre-rendered thumbnails of larger images in the volume,
however those thumbnails can still be reconstructed from the original images.

We want such a cache to survive a container restart due to a helath check failure,
emptyDir works well for this type of cache use case as well.

Persistent Data:
----------------
Sometimes we want our volume to persist data independent of the lifespan of a particular Pod,
Volume should move between nodes in the cluster if a node fails or a Pod moves to a different machine for some reason.

To acheive this Kubernetes supports a wide variety of remote network storage volumes,
including widely supported protocols like NFS or iSCSI as well as EBS, Azure Files and Disk Storage, and GCP Persistent Disk

Mounting Host File System:
--------------------------
Kubernetes supports hostPath volume which can mount arbitrary locations on the worker node in to the container.
Example above uses the hostPath volume type to mount /var/lib/kuard on the host in to the container.

Persisting Data Using Remote Disks:
-----------------------------------
Often we want the data a Pod is using to stay with the Pod, even if the Pod is restarted on a different host machine.

We can mount a remote network storage volume in to our Pod,
when using network-based storage, Kubernetes automatically mounts and unmounts the appropriate storage
whenever a Pod using that volume is scheduled on to a particular machine.

Kubernetes includes support for standard network-based protocols such as NFS and iSCSI as well as cloud provider based storage APIs

Example using NFS server:

...
# Rest of the pod definition above here
volumes:
  - name: "kuard-data"
    nfs:
	  server: my.nfs.server.local
	  path: "/exports"

Putting It All Together
=======================
Stateful applications must preserve any data and ensure access to underlying storage volume regardless of what machine the application runs on.
This can be acheived using a persistent volume backed by network-attached storage.

We also want to ensure a healthy instance of the application is running at all time,
which means we want to make sure the container running kuard is ready before we expose it to clients.

Through a combination of persistent volumes, readiness and liveness probes, and resource restrictions,
Kubernetes provides everything needed to run stateful applications reliably.

kuard-pod-full.yaml
-------------------
apiVersion: v1
kind: Pod
metadata:
  name: kuard
spec:
  volumes:
    - name: "kuard-data"
	  nfs:
	    server: my.nfs.server.local
		path: "/exports"
  containers:
    - image: gcr.io/kuar-demo/kuard-amd64:1
	  name: kuard
	  ports:
	    - containerPort: 8080
		  name: http
		  protocol: TCP
	  resources:
	    requests:
		  cpu: "500m"
		  memory: "128Mi"
		limits:
		  cpu: "1000m"
		  memory: "256Mi"
	  volumeMounts:
	    - mountPath: "/data"
		  name: "kuard-data"
	  livenessProbe:
	    httpGet:
		  path: /healthy
		  port: 8080
		initialDelaySeconds: 5
		timeoutSeconds: 1
		periodSeconds: 10
		failureThreshold: 3
	  readinessProbe:
	    httpGet:
		  path: /ready
		  port: 8080
		initialDelaySeconds: 30
		timeoutSeconds: 1
		periodSeconds: 10
		failureThreshold: 3

The manner in which persistent volumes, persistent volume claims, and dynamic volume provisioning
work together is a deep topic that has many different details. Chapter 13 deals in depth on this.

Summary:
========
Once we submit Pod manifest to the API server, scheduler finds a machine where the Pod can fit and schedules the Pod to that machine
Once scheduled, kubelet daemon on that machine is responsible for creating the containers that correspond to the Pod
kubelet daemon is also responsible for performing any health checks defined in the Pod manifest


Labels and Annotations:
=======================
Labels are key/value pairs that can be attached to Kubernetes objects
Labels can be arbitrary and are useful for attaching identifying information to Kubernetes objects
Labels provide the foundation for grouping, viewing and operating objects
Kubernetes uses labels to deal with sets of objects instead of single instances

Annotations provide storage mechanism that resembles labels
Key/value pairs designed to hold non-identifying information that can be leveraged by tools and libraries.

Label keys can be broken down into two parts: an optional prefix and a name seperated by a slash /
The prefix if specified must be a DNS sub domain with a 253 character limit.
Label key name is required and must be shorter than 63 characters.
Label key name must start with alphanumeric character and can have dashes (-), underscores (_), and dots(.) between characters

Label values are strings with a maximum length of 63 characters,
Label values must start with alphanumeric character and can have dashes (-), underscores (_), and dots(.) between characters

Valid Label Keys & Values:
==========================
Key                               Value
acme.com/app-version              1.0.0
appVersion                        1.0.0
app.version                       1.0.0
kubernetes.io/cluster-service     true

Applying Labels
---------------
Here we will take two apps alpaca and bandicoot and have two environments for each.

1. Create alpaca-prod deployment, and set ver, app, and env labels:

$ kubectl run alpaca-prod --image=gcr.io/kuar-demo/kuard-amd64:1 --replicas=2 --labels="ver=1,app=alpaca,env=prod"

2. Create alpaca-test deployment, and set ver, app, and env labels:

$ kubectl run alpaca-test --image=gcr.io/kuar-demo/kuard-amd64:2 --replicas=1 --labels="ver=2,app=alpaca,env=test"

3. Create bandicoot-prod deployment, and set ver, app, and env labels:

$ kubectl run bandicoot-prod --image=gcr.io/kuar-demo/kuard-amd64:2 --replicas=2 --labels="ver=2,app=bandicoot,env=prod"

4. Create bandicoot-staging deployment, and set ver, app, and env labels:

$ kubectl run bandicoot-staging --image=gcr.io/kuar-demo/kuard-amd64:2 --replicas=1 --labels="ver=2,app=bandicoot,env=staging"

At this point we will have four deployments:
alpaca-prod
alpaca-test
bandicoot-prod
bandicoot-staging

$ kubectl get deployments --show-labels
NAME            ...  LABELS
alpaca-prod     ...  app=alpaca, env=prod, ver=1
...
...

We can visualize the output as a Ven diagram based on the labels.

Labels can be applied or updated on objects that are already created.

$ kubectl label deployments alpaca-test "canary=true"
In this case kubectl label command will only change the label on the deployment itself;
It won't affect the objects (ReplicaSets and Pods) the deployment creates.
To change those, we will have to change the template embedded in the deployment

-L option to kubectl get command shows the label value as a column

$ kubectl get deployments -L canary
NAME                DESIRED   CURRENT  ... CANARY
alpaca-prod         2         2        ... <none>
alpaca-test         1         1        ... true
bandicoot-prod      2         2        ... <none>
bandicoot-staging   1         1        ... <none>

We can remove a label by applying a - suffix to the Key name:

$ kubectl label deployments alpaca-test "canary-"

Label Selectors:
================
Label selectors are used to filter Kubernetes objects based on a set of labels.
Selectors use a simple boolean language
They are used by end users via tools like kubectl
They are used by different types of objects such as how ReplicaSet relates to its Pods

Each deployment via a ReplicaSet creates a set of Pods using Labels specified in the template embedded in the deployment.
kubectl get pods should list the labels of all our Pods

$ kubectl get pods --show-labels

NAME                              ... LABELS
alpaca-prod-3408831585-4nzfb      ... app=alpaca,env=prod,ver=1,...
alpaca-prod-3408831585-kga0a      ... app=alpaca,env=prod,ver=1,...
alpaca-test-1004512375-3r1m5      ... app=alpaca,env=test,ver=2,...
bandicoot-prod-373860099-0t1gp    ... app=bandicoot,env=prod,ver=2,...
bandicoot-prod-373860099-k2wcf    ... app=bandicoot,env=prod,ver=2,...
bandicoot-staging-1839769971-3ndv ... app=bandicoot,env=staging,ver=2,...


If we wanted to list only the Pods that has ver label set to 2, we could use the --selector flag:

$ kubectl get pods --selector="ver=2"

NAME                                 READY     STATUS    RESTARTS   AGE
alpaca-test-1004512375-3r1m5         1/1       Running   0          3m
bandicoot-prod-373860099-0t1gp       1/1       Running   0          3m
bandicoot-prod-373860099-k2wcf       1/1       Running   0          3m
bandicoot-staging-1839769971-3ndv5   1/1       Running   0          3m

If we specify two selectors seperated by a comma, only the objects that satisfy both will be returned.

$ kubectl get pods --selector="app=bandicoot,ver=2"

NAME                                 READY     STATUS    RESTARTS   AGE
bandicoot-prod-373860099-0t1gp       1/1       Running   0          4m
bandicoot-prod-373860099-k2wcf       1/1       Running   0          4m
bandicoot-staging-1839769971-3ndv5   1/1       Running   0          4m

We can also ask if a label is one of a set of values as in the below example.

# kubectl get pods --selector="app in (alpaca, bandicoot)"

NAME                                 READY     STATUS    RESTARTS   AGE
alpaca-prod-3408831585-4nzfb         1/1       Running   0          6m
alpaca-prod-3408831585-kga0a         1/1       Running   0          6m
alpaca-test-1004512375-3r1m5         1/1       Running   0          6m
bandicoot-prod-373860099-0t1gp       1/1       Running   0          6m
bandicoot-prod-373860099-k2wcf       1/1       Running   0          6m
bandicoot-staging-1839769971-3ndv5   1/1       Running   0          6m

We can also ask if a label is set at all.

$ kubectl get deployments --selector="canary"

NAME          DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE
alpaca-test   1         1         1            1           7m

Label Selector Operators
========================

Operator                              Description

key=value                             key is set to value

key!=value                            key is not set to value

key in (value1, value2)               key is one of value1 or value2

key notin (value1, value2)            key is not one of value1 or value2

key                                   key is set

!key                                  key is not set

Label Selectors in API Objects:
-------------------------------
When Kubernetes object refers to a set of other Kubernetes objects,
a label selector in parsed structure is used.

For historical reasons there are two forms; Most objects support a newer, more powerful set of selector operators.

A selector of app=alpaca, ver in (1, 2) would be converted to this:

selector:
  matchLabels:
    app: alpaca
  matchExpressions:
    - {key: ver, operator: In, values: [1, 2]}

   =====================
  | Compact YAML Syntax |
   =====================

All of the terms are evaluated as a logical AND.
Only way to represent the != operator is to convert it to a NotIn expression with a single value.

Older form of specifying selectors used in ReplicationController only supports the = operator.
A simple set of key/value pairs that must all match a target object to be selected.

The selector app=alpaca, ver=1 would be represented like this:

selector:
  app: alpaca
  ver: 1

Annotations:
============
Annotations provide a place to store additional metadate for Kubernetes objects,
with the sole purpose of assisting tools and libraries.

Annotations are a way for other programs driving Kubernetes via an API to store some opaque data with an object.

Annotations can be used for the tool itself or to pass configuration information between external systems

Annotations are used to provide extra information about where an object came from, how to use it, or policy around that object.


Annotations are used to:
>>Keep track of a "reason" for the latest update to an object
>>Communicate a specialized scheduling policy to a specialized scheduler
>>Extend data about the last tool to update the resource and how it was updated
(Used for detecting changes by other tools and doing a smart merge)
>>Build, release, or image information that is not appropriate for labels
>>Enable the Deployment object to keep track of ReplicaSets that it is managing for rollouts
>>Prototype alpha functionality in kubernetes
(Instead of creating a first-class API field, the parameters for that functionality are instead encoded in an annotation)

Primary use case for annotations in Kubernetes is for rolling deployments.
During rolling deployments, annotations are used to keep track roll out status
and provide necessary information required to roll back a deployment to previous state.

Defining Annotations
--------------------
Annotations use the same format as label keys.
Value component of an annotation is a free-form string field.

Annotations are defined in the common metadata section in every Kubernetes object:

...
metadata:
  annotations:
    example.com/icon-url: "https://example.com/icon.png"
...

Labels and Annotations are key to understanding how key components in Kubernetes cluster work together to ensure the desired cluster state.
Using Labels and Annotations properly unlocks the true power of Kubernetes's flexibility and provides the starting point for building automation
tools and deployment work flows

Cleanup:
--------
$ kubectl delete deployments --all

Service Discovery:
==================
Dynamic nature of Kubernetes makes it easy to run a lot of things, it create problems when it comes  finding those things.
Service discovery tools help solve the problem of finding which processes are listening at which addresses for which services.

A good service discovery system will enable users to resolve this information quickly and reliably.

Domain Name System(DNS) is the traditional system of service discovery on the Internet,
however DNS is designed for relatively stable name resolution with wide and efficient caching.

Unfortunately many systems like Java lookup a name in DNS directly and never resolve,
This can lead to clients caching stale mappings and talking to the wrong IP.

Even with short TTLs and well-behaved clients,
there is a natural delay between when a name resolution changes and the client notices.

The Service Object:
-------------------
Real service discovery in Kubernetes starts with a Service object.

A Service Object is a way to create a named label selector,
as we will see the Service Object does some other nice thins for us too.

We can use kubectl expose to create a service.
Let's create some deployments and services to see how they work

$ kubectl run alpaca-prod --image=gcr.io/kuar-demo/kuard-amd64:1 --replicas=3 --port=8080 --labels="ver=1,app=alpaca,env=prod"

$ kubectl expose deployment alpaca-prod

$ kubectl run bandicoot-prod --image=gcr.io/kuar-demo/kuard-amd64:2 --replicas=3 --port=8080 --labels="ver=2,app=alpaca,env=prod"

$ kubectl expose deployment bandicoot-prod

$ kubectl get services -o wide

NAME             CLUSTER-IP    ... PORT(S)  ... SELECTOR
alpaca-prod      10.115.245.13 ... 8080/TCP ... app=alpaca,env=prod,ver=1
bandicoot-prod   10.115.242.3  ... 8080/TCP ... app=bandicoot,env=prod,ver=2
kubernetes       10.115.240.1  ... 443/TCP  ... <none>

If we look at SELECTOR column,
we see that the alpaca-prod service simply gives a name to a selector and specifies which ports to talk to for that service.

The kubectl expose command will pull both the label selector and the relevant port from the deployment definition.

Our Services are assigned a new type of virtual IP called a Cluster IP,
This is the IP address the system will load balance across all of the pods that are identified by the selector

To interact with serviec, we are going to port-forward to one of the alpaca pods.

$ ALPACA_POD=$(kubectl get pods -l app=alpaca -o jsonpath='{.items[0].metadata.mame}')

$ kubectl port-forward $ALPACA_POD 48858:8080

Leave the above command running and access http://loaclhost:48858 from a browser.

Service DNS
-----------
Kubernetes provides a DNS service exposed to Pods running int the cluster.
Kubernetes DNS service is installed as a system component when the cluster was first created.

Kubernetes DNS service provides DNS names for cluster IPs

We can try this by expanding the "DNS Query" section on the kuard server status page.
Query the A record for alpaca-prod, output should look something like below

;; opcode: QUERY, status: NOERROR, id: 12071
;; flags: qr aa rd ra; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 0

;; QUESTION SECTION:
;alpaca-prod.default.svc.cluster.local.	IN	 A

;; ANSWER SECTION:
alpaca-prod.default.svc.cluster.local.	30	IN	A	10.115.245.13

Full DNS name here is alpaca-prod.default.svc.cluster.local

Let us break this down..

alpaca-prod
>Name of the service in question

default
>Namespace our service is in

svc
>Recognizing that this is a service, This allows Kubernetes to expose other types of things as DNS in the future

cluster.local
>Base domain name for the cluster, this is the default that we will see for most clusters.
Administrators may change this to allow unique DNS names across multiple clusters

We can use just the service name (alpaca-prod) when referring to a service in its namespace
We can refer to a service in another namespace with service-name.namespace (alpaca-prod.default)

Readiness Checks
================
When an application starts up, there is usually some amount of initialization that can
take anywhere from under a second to several minutes.

Service object tracks which of our Pods are ready via a readiness check.

Let's modify our deployment to add a readiness check:

$ kubectl edit deployment/alpaca-prod

Add the following section to alpaca-prod deployment manifest

spec:
  ...
  template:
    ...
	spec:
	  containers:
	    ...
		name: alpaca-prod
		readinessProbe:
		  httpGet:
		    path: /ready
			port: 8080
		  periodSeconds: 2
		  initialDelaySeconds: 0
		  failureThreshold: 3
		  successThreshold: 1

Now Pods of this deployment will be checked for readiness via an HTTP GET to /ready on port 8080
This check is done every 2 seconds starting as soon as the Pod comes up.
If three successive checks fail, then the Pod will be considered not ready.
If one check succeeds, then the Pod will again be considered ready

----------------------------------
|Only Ready Pods are Sent Traffic|
----------------------------------

Updating deployment definition with "kubectl edit" command will delete and recreate the Pods,
We need to restart our port-forward command from earlier like below

$ ALPACA_POD=$(kubectl get pods -l app=alpaca -o jsonpath='{.items[0].metadata.mame}')

$ kubectl port-forward $ALPACA_POD 48858:8080

Open http://loaclhost:48858 in a browser, and we should see the debug page for the instance of kuard
Expanding the "Readiness Probe" section, we should see the page update every time there is a new readiness check from the system

Endpoints are lower level way of finding what a service is sending traffic to.

$ kubectl get endpoints alpaca-prod --watch

--watch flag specified here causes Kubectl command to hang around and output any updates

Now go back to browser and hit the "Fail" link for the readiness check
We should see that the server is now returning 500s for all readiness checks

After three failures the server is removed from the list of endpoints for the service.

Hit the "Succeed" link and notice that after a single readiness check the endpoint is added back

Readiness check is a way for an overloaded or sick server to signal to the system that it doesn't want to receive traffic anymore.
This is a great way to implement graceful shutdown...
The server can signal that it no longer wants traffic, wait until existing connections are closed and then cleanly exit.

NodePort Service
================
NodePort builds on ClusterIP by exposing the service on every node in the cluster on a specific port
User can also specify the port, NodePort can be integrated with hardware or software load balancers to expose the service further

If we have a NodePort service then,
Every node in the cluster will forward incoming traffic to NodePort port to the service

Let us modify the alpaca-prod service to make it a NodePort

$ kubectl edit service alpaca-prod

Change the spec.type field to NodePort in the service definition
We can also specify --type=NodePort when creating the service with kubectl expose command

$ kubectl describe service alpaca-prod

Name:                   alpaca-prod
Namespace:              default
Labels:                 app=alpaca
                        env=prod
                        ver=1
Annotations:            <none>
Selector:               app=alpaca,env=prod,ver=1
Type:                   NodePort
IP:                     10.115.245.13
Port:                   <unset> 8080/TCP
NodePort:               <unset> 32711/TCP
Endpoints:              10.112.1.66:8080,10.112.2.104:8080,10.112.2.105:8080
Session Affinity:       None
No events.

Here we can see that the system assigned port 32711 to alpaca-prod service.
Now we can hit any of our cluster nodes on port 32711 to access the alpaca-prod service.

In case our cluster is not on the same network, then we can use SSH tunneling like below to access the NodePort service

$ ssh <node> -L 8080:localhost:32711

Now if we navigate to http://localhost:8080 we will be connected to alpaca-prod service.
Each request will be randomly directed to one of the Pods that implement the service.

LoadBalancer Service
====================
LoadBalancer builds on NodePort by creating and configuring a new load balancer to direct traffic at nodes in our cluster

Let us modify the alpaca-prod service to make it a LoadBalancer

$ kubectl edit service alpaca-prod

Change the spec.type field to LoadBalancer in the service definition

If we run "kubectl get services" immediately, we will see the EXTERNAL-IP column is <pending>
Kubernetes is still creating and configuring the Cloud Load Balancer for us.

$ kubectl describe service alpaca-prod

Name:                   alpaca-prod
Namespace:              default
Labels:                 app=alpaca
                        env=prod
                        ver=1
Selector:               app=alpaca,env=prod,ver=1
Type:                   LoadBalancer
IP:                     10.115.245.13
LoadBalancer Ingress:   104.196.248.204
Port:                   <unset>	8080/TCP
NodePort:               <unset>	32711/TCP
Endpoints:              10.112.1.66:8080,10.112.2.104:8080,10.112.2.105:8080
Session Affinity:       None
Events:
  FirstSeen ... Reason                Message
  --------- ... ------                -------
  3m        ... Type                  NodePort -> LoadBalancer
  3m        ... CreatingLoadBalancer  Creating load balancer
  2m        ... CreatedLoadBalancer   Created load balancer

Here we can see "LoadBalancer Ingress: 104.196.248.204" for alpaca-prod service.
Depending on the cloud provider, it may take a little while for the load balancer to be fully operational

Endpoints
=========
For every Service object, Kubernetes creates a buddy Endpoints object that contains the IP addresses for that service.

$ kubectl describe endpoints alpaca-prod

Name:           alpaca-prod
Namespace:      default
Labels:         app=alpaca
                env=prod
                ver=1
Subsets:
  Addresses:            10.112.1.54,10.112.2.84,10.112.2.85
  NotReadyAddresses:    <none>
  Ports:
    Name        Port    Protocol
    ----        ----    --------
    <unset>     8080    TCP

No events.

To use a service, application can talk to Kubernetes API directly to look up endpoints and call them.
Kubernetes API also has the capability to "watch" objects and be notified as soon as they change,
this way a client can react immediately as soon as the IPs associated with a service change.

$ kubectl get endpoints alpaca-prod --watch
this command will output the current state of the endpoint and waits there

NAME          ENDPOINTS                                            AGE
alpaca-prod   10.112.1.54:8080,10.112.2.84:8080,10.112.2.85:8080   1m

Open another terminal window and delete and recreate the alpaca-prod deployment

$ kubectl delete deployment alpaca-prod

$ kubectl run alpaca-prod --image=gcr.io/kuar-demo/kuard-amd64:1 --replicas=3 --port=8080 --labels="ver=1,app=alpaca,env=prod"

If we look at output of "kubectl get endpoints alpaca-prod --watch" command,
We will see that the command reflects the most up-to-date set of IP addresses associated with the service.

Endpoints object is great if your code is built to run on Kubernetes from the start,
however most projects aren't in this position

Manual Service Discovery
========================
Kubernetes services are built on top of label selectors over Pods
That means we can use Kubernetes API to do rudimentary service discovery without using a Service object 

With kubectl and with API we can easily see what IPs are assigned to each Pod in our deployments.

$ kubectl get pods -o wide --show-labels

NAME                            ... IP          ... LABELS
alpaca-prod-12334-87f8h    ... 10.112.1.54 ... app=alpaca,env=prod,ver=1
alpaca-prod-12334-jssmh    ... 10.112.2.84 ... app=alpaca,env=prod,ver=1
alpaca-prod-12334-tjp56    ... 10.112.2.85 ... app=alpaca,env=prod,ver=1
bandicoot-prod-5678-sbxzl  ... 10.112.1.55 ... app=bandicoot,env=prod,ver=2
bandicoot-prod-5678-x0dh8  ... 10.112.2.86 ... app=bandicoot,env=prod,ver=2

This is great, but what if we have a ton of pods ?
We can filter the output based on labels applied as part of the deployment.

$ kubectl get pods -o wide --selector=app=alpaca,env=prod

NAME                         ... IP          ...
alpaca-prod-3408831585-bpzdz ... 10.112.1.54 ...
alpaca-prod-3408831585-kncwt ... 10.112.2.84 ...
alpaca-prod-3408831585-l9fsq ... 10.112.2.85 ...

We can always use labels to identify the set of Pods we are interested in,
get all of the Pods for those labels and dig out the IP address.

But keeping the correct set of labels to use in sync can be tricky!!!


kube-proxy and Cluster IP
=========================
Cluster IPs are stable virtual IPs that load-balance traffic across all of the endpoints in a service.
This magic is performed by kube-proxy running on every node in the cluster

kube-proxy watches for new services in the cluster via API server,
It then programs a set of iptables rules in the kernel of that host to rewrite the destination of packets,
so they are directed at one of the endpoints for that service

If the set of endpoints for a service changes due to Pods coming and going or due to failed readiness check,
then the set of iptables rules is rewritten.

ClusterIP is usually assigned by the API server as the Service is created,
However when creating the Service user can specify a specific ClusterIP

Once set the ClusterIP can not be modified without deleting and recreating the Service

Kubernetes service address range is configured using the --service-cluster-ip-range flag on kube-apiserver binary.
Service address range should not overlap with IP subnets and ranges assigned to each Docker bridge or Kubernetes node.

Any explicit ClusterIP requested must come from a range that is not already in use.


ClusterIP Environment Variables
===============================
Users should be using DNS services to find Cluster IPs,
however there are some older mechanisms that may still be in use.

One such old mechanism is injecting a set of environment variables in to Pods as they start up.

$ BANDICOOT_POD=$(kubectl get pods -l app=bandicoot -o jsonpath='{.items[0].metadata.name}')

$ kubectl port-forward $BANDICOOT_POD 48858:8080

Browse to http://localhost:48858 to see the status page for this server.
Expand the "Server Env" section and note the set of environment variables for the alpaca Service

Two main environment variables to use are ALPACA_PROD_SERVICE_HOST and ALPACA_PROD_SERVICE_PORT.

Problem with the environment variable approach is that it requires resources to be created in a specific order.
Services must be created before the Pods that reference them,
this can introduce quite a bit of complexity when deploying a set of Services that make up a larger application.

DNS is probably a better option for Service Discovery

Cleanup
-------

$ kubectl delete services,deployments -l app

Once our application can dynamically find Service and react to dynamic placement of those applications,
we are free to stop worrying about where things are running and when they move.

It is a critical piece of the puzzle to start to think about services in a logical way and let Kubernetes
take care of the details of container placement.

ReplicaSets
===========

We usually want multiple replicas of our container running at a particular time.
There are a variety of reasons for this type of replication:

Redundancy: Multiple running instances mean failure can be tolerated.

Scale: Multiple running instances mean that more requests can be handled.

Sharding: Different replicas can handle different parts of a computation in parallel.


Logically a user managing a replicated set of Pods considers them as a single entity to be defined and managed
This is precisely what a ReplicaSet is, it acts as a cluster wide Pod manager ensuring right types and number of Pods are running at all times.

ReplicaSets are the building blocks used to describe common application deployment patterns,
they provide the underpinnings of self-healing for our applications at the infrastructure level.

Pods managed by ReplicaSets are automatically rescheduled under certain failure conditions such as node failure and network partitions.

Easiest way to think of a ReplicaSet is that it combines a cookie cutter and a desired number of cookies in to a single API object.
We define a specification for the Pods we want to create (the "cookie cutter") and a desired number of replicas ("number of cookies")

Additionally we need to define a way of finding Pods that the ReplicaSet should control.


Reconciliation Loops
====================
Central concept behind a reconciliation loop is the notion of desired state and observed or current state.

Desired state is the state we want,
Desired number of replicas and the definition of the Pod to replicate with the ReplicaSet
i.e. desired state is that there are three replicas of a Pod running kuard server.

Current state is the currently observed state of the system.
i.e. there are only two Pods currently running kuard server 

Reconciliation Loop is constantly running observing the current state of the world and
taking action to try to make the observed state match the desired state

Example: reconciliation loop creates a new kuard Pod in a effort to make the observed state match the desired state of three replicas.

Reconciliation loop is an inherently goal-driven, self-healing system, yet it can often be easily expressed in a few lines of code.

Reconciliation loop for ReplicaSet is a single loop, and yet it handles both user actions to scale up or scale down the ReplicaSet
as well as node failures or nodes rejoining the cluster after being absent.


Relating Pods and ReplicaSets
=============================
One of the key themes that runs through Kubernetes is decoupling.
It's important that all of the core concepts of Kubernetes are modular with respect to each other and that they are swappable
and replaceable with other components.

The relationship between ReplicaSets and Pods is loosely coupled,
Though ReplicaSets create and manage Pods, they do not own the Pods they create.

ReplicaSets use label queries to identify the set of Pods they should be managing,
ReplicaSets then use Pod API that we used to create Pods that they are managing.

In a similar decoupling, ReplicaSets that create multiple Pods and the Services that
load-balance to those Pods are also totally separate, decoupled API objects.

In addition to supporting modularity, the decoupling of Pods and ReplicaSets
enables several important behaviors discussed in the following sections.

Adopting Existing Containers
----------------------------
Assume we have a single Pod with our application running and traffic to our Pod is being load balanced

If ReplicaSets owned the Pods then created,
then the only way to start replicating our Pod would be to delete it and relaunch it via a ReplicaSet
This might be disruptive as there would be a moment in time when there would be no copies of our container running.

As ReplicaSets are decoupled from the Pods they manage, we can simply create a ReplicaSet that will "adopt" the existing Pod,
and scale out additional copies of those containers. In this way we can seamlessly move from a single Pod to a replicated set of Pods managed by a ReplicaSet

Quarantining Containers
-----------------------
Pod level health checks will automatically restart a Pod when our code misbehaves.
However if our health checks are incomplete, a Pod can be misbehaving and still be part of the replicated set.

If we simply kill the misbehaving Pod, that would leave our developers with only logs to debug.

We can modify the set of labels on the sick Pod and disassociate it from the ReplicaSet and Service,
so that our developers can debug the Pod and ReplicaSet controller will notice that a Pod is missing and create a new copy

Designing with ReplicaSets
==========================
ReplicaSets are designed to represent a single scalable microservice inside our architecture.
Every Pod created by the ReplicaSet controller is entirely homogeneous.
These Pods and fronted by a Kubernetes service load balancer which spreads traffic across the Pods
ReplicaSets are designed for stateless or nearly stateless services

When a ReplicaSet is scaled down, an arbitrary Pod is selected for deletion.
Our application's behavior should not change because of such a scale-down operation.

ReplicaSet Spec
===============
All ReplicaSets must have:
>A unique name defined using metadata.name field
>A spec section that describes the number of Pods that should be running on the cluster at any given time
>A Pod template that describes the Pod to be created when the defined number of replicas is not met.


Minimal ReplicaSet definition

kuard-rs.yaml
-------------
apiVersion: extensions/v1beta1
kind: ReplicaSet
metadata:
  name: kuard
spec:
  replicas: 1
  template:
    metadata:
	  labels:
	    app: kuard
		version: "2"
	spec:
	  containers:
	    - name: kuard
		  image: "gcr.io/kuar-demo/kuard-amd64:2"


Pod Templates:
--------------
Pods are created by ReplicaSet using a Pod template that is contained in the ReplicaSet specification.
Pods are created exactly in the same manner as we created Pods from a YAML file previously
Instead of using a YAML file, ReplicaSet controller creates and submits a Pod manifest based on the Pod template.

Example Pod template in a ReplicaSet:

template:
  metadata:
    labels:
	  app: helloworld
	  version: v1
  spec:
    containers:
	  - name: helloworld
	    image: kelsyhightower/helloworld
		ports:
		  - containerPort: 80

Labels:
-------
The ReplicaSet controller discovers the set of Pods for a particular ReplicaSet using labels.
Labels are used to filter Pod listings and track Pods running within a cluster.

i.e. when a ReplicaSet is initially created, it fetches Pod listing from Kubernetes API and filters the results by labels.
based on the number of Pods returned by the query, the ReplicaSet either deletes or creates Pods to match the desired number of replicas.

Labels used for filtering are defined in the ReplicaSet spec section and are the key to understanding how ReplicaSets work.

NOTE:
The Selector in the ReplicaSet spec section should be a proper subset of the labels in the Pod template

Creating a ReplicaSet
=====================

ReplicaSets are created by submitting a ReplicaSet object to Kubernetes API.


kuard-rs.yaml
-------------
apiVersion: extensions/v1beta1
kind: ReplicaSet
metadata:
  name: kuard
spec:
  replicas: 1
  template:
    metadata:
	  labels:
	    app: kuard
		version: "2"
	spec:
	  containers:
	    - name: kuard
		  image: "gcr.io/kuar-demo/kuard-amd64:2"
		  
$ kubectl apply -f kuard-rs.yaml
replicaset "kuard" created

Once the kuard ReplicaSet has been accepted, ReplicaSet controller will detect that there are no kuard Pods
running that match the desired state, and a new kuard Pod will be created based on the contents of the Pod template.

$ kubectl get pods
NAME         READY  STATUS  RESTARTS  AGE
kuard-yvzgd  1/1    Running 0         11s

Inspecting a ReplicaSet
=======================
kubectl describe command will provide more information about the state of a ReplicaSet

$ kubectl describe rs kuard
Name:        kuard
Namespace:   default
Image(s):    kuard:1.9.15
Selector:    app=kuard,version=2
Labels:      app=kuard,version=2
Replicas:    1 current / 1 desired
Pods Status: 1 Running / 0 Waiting / 0 Succeeded / 0 Failed
No volumes

Here we can see the label selector for the ReplicaSet, as well as the state of all of the replicas managed by the ReplicaSet

Finding a ReplicaSet from a Pod
-------------------------------

Sometimes we might want to check if a Pod is being managed by a ReplicaSet

ReplicaSet controller adds an annotation to every Pod that it creates.
key for the annotation is kubernetes.io/created-by

We have to run the below command and look for the kubernetes.io/created-by entry in the annotations section

$ kubectl get pods <pod-name> -o yaml

NOTE:
Annotations are best-effort; they are created when the Pod is created by the ReplicaSet
Annotation can be removed by a Kubernetes user at any time.

Finding a Set of Pods for a ReplicaSet
--------------------------------------
We can also determine the set of Pods managed by a ReplicaSet

First we have to get the label selectors of the ReplicaSet using kubectl describe rs command,
then use the label selectors to get te list of Pods managed by the ReplicaSet

$ kubectl describe rs <ReplicaSet-Name>

$ kubectl get pods -l app=kuard,version=2

This is exactly the same query that the ReplicaSet executes to determine the current number of Pods.

Scaling ReplicaSets
===================
ReplicaSets are scaled up or down by updating the spec.replicas key on the ReplicaSet object stored in Kubernetes
When a ReplicaSet is scaled up, new Pods are submitted to Kubernetes API using the Pod template defined in the ReplicaSet

Imperative Scaling with kubectl scale
-------------------------------------

$ kubectl scale replicasets kuard --replicas=4

Imperative commands like kubectl scale are useful for demonstrations and quick reactions to emergency situations.
If is important to also update any text file configurations to match the number of replicas that we set via imperative scale command.

Imperative changes should be immediately be followed by a declarative change in source control

Declarative Scaling with kubectl apply
--------------------------------------
In a declarative world, we make changes by editing the configuration file in version control and then applying those changes to our cluster.
To scale kuard ReplicaSet, edit the kuard-rs.yaml configuration file and set the replicas count to 3

...
spec:
  replicas: 3
...

$ kubectl apply -f kuard-rs.yaml
replicaset "kuard" configured

ReplicaSet controller with detect the change in number of desired Pods and submit new Pods to Kubernetes API

$ kubectl get pods
NAME         READY  STATUS  RESTARTS  AGE
kuard-3a2sb  1/1    Running 0         26s
kuard-wuq9v  1/1    Running 0         26s
kuard-yvzgd  1/1    Running 0         2m

Autoscaling a ReplicaSet
------------------------
Kubernetes supports scaling with Horizontal Pod Autoscaling based on:

> CPU usage
> Memory consumption
> Custom application metrics

NOTE:
HPA requires the presence of heapster Pod in our cluster
heapster keeps rack of metrics and provides an API for consuming metrics HPA uses when making scaling decisions.

Most installations of Kubernetes include heapster by default,
we can validate the presence of heapster by listing Pods in kube-system namespace

$ kubectl get pods --namespace=kube-system


Horizontal scaling involves creating additional replicas of a Pod,
Vertical scaling is not currently implemented in Kubernetes

Autoscaling based on CPU
------------------------
To scale a ReplicaSet we can run a command like the following:

$ kubectl autoscale rs kuard --min=2 --max=5 --cpu-percent=80

This command creates an autoscaler that scales between tow and five replicas with a CPU threshold of 80%

We can list the horizontalpodautoscalers resource we created by running the below command

$ kubectl get hpa

NOTE:
There is no direct link between Horizontal Pod Autoscaler and the ReplicaSet because of the decoupled nature of Kubernetes


WARNING:
Its a bad idea to combine both autoscaling and imperative or declarative management of the number of replicas.
If both we and an autoscaler are attempting to modify the number of replicas, we will clash resulting in unexpected behavior

Deleting ReplicaSets
====================
When a ReplicaSet is no longer needed it can be deleted using kubectl delete command.

$ kubectl delete rs kuard

By default, this command also deletes the Pods that are managed by the ReplicaSet

Running kubectl get pods command will not show us any kuard Pods created by kuard ReplicaSet

$ kubectl get pods

If we don't want to delete the Pods that are being managed by the ReplicaSet,
then we can set the --cascade flag to fase as shown below.

$ kubectl delete rs kuard --cascade=false

DaemonSets
**********
DaemonSets are used to replicate a set of Pods to schedule a single Pod on every node within the cluster
DaemonSet ensures a copy of a Pod is running accross a set of nodes in a Kubernetes cluster.

Generally the motivation for replicating a Pod to every node is to land some sort of agent or daemon on each node
DaemonSets are used to deploy system daemons such as log collectors and monitoring agents, which typically must run on every node.

DaemonSets share similar functionality with ReplicaSets;
both create Pods that are expected to be long-running services and ensure that desired state and observed state of the cluster match.

ReplicaSets should be used when our application is completely decoupled from the node and we can run multiple copies on a given node.
DaemonSets should be used when a single copy of our application must run on all or a subset of the nodes in our cluster.

DaemonSet Scheduler
===================
By default a DaemonSet will schedule a copy of a Pod on every node in the cluster unless a node selector is used.
Node selector will limit eligible nodes to those with a matching set of labels.

DaemonSets determine which node a Pod will run on at Pod creation time by specifying the nodeName field in the Pod spec.
As a result Pods created by DaemonSets are ignored by the Kubernetes scheduler.

Like ReplicaSets, DaemonSets are managed by a reconciliation loop that measures the desired state (a Pod is present on all nodes)
with the observed state (is the Pod present on a particular node?) and the DaemonSet controller creates a Pod on each node that
does not currently have a matching Pod.

If a new node is added to the cluster, then the DaemonSet controller notices that it is missing a Pod and adds the Pod to the new node.

Like ReplicaSets, DaemonSets do not own the Pods managed by them.

Creating DaemonSets
===================
DaemonSets are created by submitting DaemonSet configuration to Kubernetes API server.

Below DaemonSet example will create a fluentd logging agent on every node in the target cluster

fluentd.yaml
------------
apiVersion: extensions/v1beta1
kind: DaemonSet
metadata:
  name: fluentd
  namespace: kube-system
  labels:
    app: fluentd
spec:
  template:
    metadata:
	  labels:
	    app: fluentd
	spec:
	  containers:
	  - name: fluentd
	    image: fluentd/fluentd:v0.14.10
		resources:
		  limits:
		    memory: 200Mi
		  requests:
		    cpu: 100m
			memory: 200Mi
		  volumeMounts:
		  - name: varlog
		    mountPath: /var/log
		  - name: varlibdockercontainers
		    mountPath: /var/lib/docker/containers
			readOnly: true
		terminationGracePeriodSeconds: 30
		volumes:
		- name: varlog
		  hostPath:
		    path: /var/log
		- name: varlibdockercontainers
		  hostPath:
		    path: /var/lib/docker/containers


DaemonSets require a unique name accross all DaemonSets in a given Kubernetes namespace.
Each DaemonSet must include a Pod template spec as in ReplicaSet

We can use kubectl apply command to submit the DaemonSet to Kubernetes API

$ kubectl apply -f fluentd.yaml
daemonset "fluentd" created

We can query the current state of fluentd DaemonSet using kubectl describe command

$ kubectl describe daemonset fluentd --namespace=kube-system
Name:           fluentd
Image(s):       fluentd/fluentd:v0.14.10
Selector:       app=fluentd
Node-Selector:  <none>
Labels:         app=fluentd
Desired Number of Nodes Scheduled: 3
Current Number of Nodes Scheduled: 3
Number of Nodes Misscheduled: 0
Pods Status: 3 Running / 0 Waiting / 0 Succeeded / 0 Failed

$ kubectl get pods -o wide
NAME            AGE   NODE
fluentd-1q6c6   2m    k0-default-pool-35609c18-z7tb
fluentd-mwi7h   2m    k0-default-pool-35609c18-ydae
fluentd-zr617   2m    k0-default-pool-35609c18-pol3

With the fluentd DaemonSet in place,
adding a new node to the cluster will result in a new fluentd Pod being deployed to that node automatically

Limiting DaemonSets to Specific Nodes
=====================================
There are some cases where we want to deploy a Pod only to a subset of nodes.

Maybe we have a workload that requires a GPU or access to fast storage only available on a subset of nodes in our cluster.
In cases like this node labels can be used to tag specific nodes that meet workload requirements.

Adding Labels to Nodes
----------------------
First step in limiting DaemonSets to specific nodes is to add the desired set of labels to a subset of nodes.

Below command adds the ssd=true label to a single node.

$ kubectl label nodes k0-default-pool-35609c18-z7tb ssd=true
node "k0-default-pool-35609c18-z7tb" labeled

Just like with other Kubernetes resources, listing nodes without a label selector returns all nodes in the cluster

$ kubectl get nodes
NAME                            STATUS   AGE
k0-default-pool-35609c18-pol3   Ready    1d
k0-default-pool-35609c18-ydae   Ready    1d
k0-default-pool-35609c18-z7tb   Ready    1d

We can filter nodes based on labels using a label selector as below

$ kubectl get nodes --selector ssd=true
NAME                            STATUS  AGE
k0-default-pool-35609c18-z7tb   Ready   1d

Node Selectors
--------------
Node selectors can be used to limit what nodes a Pod can run on in a given Kubernetes cluster.
Node selectors are defined as part of the Pod spec when creating a DaemonSet.

nginx-fast-storage.yaml
-----------------------
apiVersion: extensions/v1beta1
kind: "DaemonSet"
metadata:
  labels:
    app: nginx
	ssd: "true"
  name: nginx-fast-storage
spec:
  template:
    metadata:
	  labels:
	    app: nginx
		ssd: "true"
	spec:
	  nodeSelector:
	    ssd: "true"
	  containers:
	    - name: nginx
		  image: nginx:1.10.0

$ kubectl apply -f nginx-fast-storage.yaml
daemonset "nginx-fast-storage" created

Since there is only one node with the ssd=true label, nginx-fast-storage Pod will only run on that node.

$ kubectl get pods -o wide
NAME                       STATUS    NODE
nginx-fast-storage-7b90t   Running   k0-default-pool-35609c18-z7tb

Adding the ssd=true label to additional nodes will cause the nginx-fast-storage Pod to be deployed on those nodes.
Inverse is also true, if a required label is removed from a node, the Pod will be removed by the DaemonSet controller

Updating DaemonSet
==================
Prior to Kubernetes 1.6 the only way to update Pods managed by a DaemonSet was to update the DaemonSet and
then manually delete each Pod that was managed by the DaemonSet so that it would be recreated with the new configuration

Kubernetes 1.6 introduced feature equivalent to Deployment object for DaemonSets to manage roll out inside a cluster

Updating a DaemonSet by Deleting Individual Pods
------------------------------------------------
If we are using a pre 1.6 version of Kubernetes, then we can run the below script to update one DaemonSet Pod every 60 seconds;

PODS=$(kubectl get pods -o jsonpath -template='{.items[*].metadata.name}'
for x in $PODS; do
  kubectl delete pods $(x)
  sleep 60
done

An alternative easier approach is to delete the DaemonSet and create a new DaemonSet with the updated configuration.
However this approach has a major disadvantage by causing downtime.
i.e. when a DaemonSet is deleted all Pods managed by that DaemonSet will also be deleted.

Rolling Update of a DaemonSet
-----------------------------
With Kubernetes 1.6, DaemonSets can be rolled out using the same rolling update strategy that deployments use.
However for backward compatibility the default update strategy is the delete method described in previous section

We need to configure the update strategy using the spec.updateStrategy.type field with value RollingUpdate

When a DaemonSet has an update strategy of RollingUpdate,
any change to the spec.template field or subfields in the DaemonSet will initiate a rolling update.

Rolling update strategy gradually updates members of a DaemonSet until all of the Pods are running the new configuration.

There are two parameters that controll the rolling update of a DaemonSet

> spec.minReadySecond
This determines how long a Pod must be "ready" before the rolling update process proceeds to upgrade subsequent Pods.

> spec.updateStrategy.rollingUpdate.maxUnavailable
This indicates how many Pods may be simultaneously updated by the rolling update

We will likely want to set spec.minReadySecond to a reasonably long value,
example 30-60 seconds, to ensure that our Pod is truly healthy before the roll out proceeds.

Setting for spec.updateStrategy.rollingUpdate.maxUnavailable is more likely to be application dependent
Setting it to 1 is a safe strategy, increasing the maximum unavailability will make our roll out move faster,
but increase the "blast radius" of a failed roll out.

Once a rolling update has started we can use kubectl rollout commands to see the current status of a DaemonSet roll out.

$ kubectl rollout status daemonSets my-daemon-set

Deleting the DaemonSet
======================

$ kubectl delete -f fluentd.yaml

Deleting a DaemonSet will also delete all the Pods being managed by that DaemonSet.
Setting --cascade flag to false will only delete the DaemonSet and not the Pods

$ kubectl delete -f fluentd.yaml --cascade=false

Jobs
****
So far we have focused on long running processes such as databases and web applications.
These type of workloads run until either they are upgraded or the service is no longer needed.

There is often need to run short-lived, one-off tasks.
Job object is made for handling these type of tasks.

A Job creates Pods that run until successful termination (i.e., exit with 0)
In contrast a regular Pod will continually restart regardless of the exit code.

The Job Object
==============
The Job object is responsible for creating and managing pods defined in a template in the Job specification.
These Pods generally run until successful completion, the Job object coordinates running a number of Pods in parallel.

If the Pod fails before a successful termination,
the Job controller will create a new Pod based on the Pod template in the Job specification.

Given that Pods have to be scheduled,
there is a chance that our Job will not execute if the required resources are not found by the scheduler

Due to the nature of distributed, during certain failure scenarios there is a small chance of duplicate Pods being created for a specific task.

Job Pattern
===========
Jobs are designed to manage batch-like workloads where work items are processed by one or more Pods.
By default each Job runs a single Pod once until successful termination.

Job pattern is defined by tow primary attributes of a Job
> Number of Job completion
> Number of Pods to run in parallel

In case of the "run once until completion" pattern,
the completion and parallelism parameters are set to 1.

Job Patterns
------------

Type:         One Shot
Use Case:     Database migration
Behavior:     A single Pod running once until successful termination
Completions:  1
Parallelism:  1

Type:         Parallel fixed completions
Use Case:     Multiple Pods processing a set of work in parallel
Behavior:     One or more Pods running one or more times until reaching a fixed completion count
Completions:  1+
Parallelism:  1+

Type:         Work queue: parallel Jobs
Use Case:     Multiple Pods processing from a centralized work queue
Behavior:     One or more Pods running once until successful termination
Completions:  1
Parallelism:  2+

One Shot
--------
Provides a way to run a single Pod once until successful termination.

Pod is submitted to Kubernetes API using a Pod template defined in the Job configuration
Once the Job is up and running, the Pod backing the Job is monitored for successful termination

A Job can fail for any number of reasons including an application error, an uncaught exception during runtime,
or a node failure before the Job has a chance to complete.

In all cases Job controller is responsible for recreating the Pod until a successful termination occurs.


Creating a One Shot Job using kubectl run command....

$ kubectl run -i oneshot --image=gcr/kuar-demo/kuard-amd64:1 --restart=OnFailure \
  -- --keygen-enable --keygen-exit-on-complete --keygen-num-to-gen 10

-i option indicates that this is an interactive command,
kubectl will wait until the Job is running and then show the log output from the first pod in the Job

All of the options after -- are command line arguments to the container image.
These instruct our test server to generate 10 4096 bit SSH keys and then exit.

After the Job has completed, the Job object and related Pods are still around, so that we can inspect the log output.
Completed Job won't show up in kubectl get jobs command output unless we pass the -a flag

$ kubectl get jobs -a

$ kubectl delete jobs oneshot

Creating one shot Job using a configuration file.

job-oneshot.yaml
----------------
apiVersion: batch/v1
kind: Job
metadata:
  name: oneshot
  labels:
    chapter: jobs
spec:
  template:
    metadata:
	  labels:
	    chapter: jobs
	spec:
	  containers:
	  - name: kuard
	    image: gcr.io/kuar-demo/kuard-amd64:1
		imagePullPolicy: Always
		args:
		- "--keygen-enable"
		- "--keygen-exit-on-complete"
		- "--keygen-num-to-gen=10"
	  restartPolicy: OnFailure

Submit the Job to Kubernetes API using kubectl apply

$ kubectl apply -f job-oneshot.yaml
job "oneshot" created

Describe the oneshot job

$ kubectl describe jobs oneshot
Name:           oneshot
Namespace:      default
Image(s):       gcr.io/kuar-demo/kuard-amd64:1
...
Parallelism:    1
Completions:    1
...
...
... SuccessfulCreate   Created pod: oneshot-4kfdt

View logs of the Pod created by the Job

$ kubectl logs oneshot-4kfdt

NOTE:
You may have noticed that we did not specify and labels when creating the Job object.

Because Jobs have a finite beginning and ending, it is common for users to create many of them.
This makes picking unique labels more difficult and more critical.

For this reason, the Job object will automatically pick a unique label and use it to identify the Pods it creates.

In advanced scenarios such as swapping out a running Job without killing the Pods it is managing,
users can choose to turn off this automatic behavior and manually specify labels and selectors.

Pod Failure:
------------
What happens when the Job could not complete successfully due to some failure?

Let's modify the arguments to kuard in our configuration file to cause it to fail out
with a nonzero exit code after generating three keys as shown below.

job-oneshot-failure1.yaml
-------------------------
...
spec:
  template:
    spec:
	  containers:
	    ...
		args:
		- "--keygen-enable"
		- "--keygen-exit-on-complete"
		- "--keygen-exit-code=1"
		- "--keygen-num-to-gen=3"
...

Launch this Job with kubectl apply command

$ kubectl apply -f job-oneshot-failure1.yaml

Look at the Pod status

$ kubectl get pods -a -l job-name=oneshot
NAME            READY   STATUS             RESTARTS   AGE
oneshot-3ddk0   0/1     CrashLoopBackOff   4          3m

Here we see that the same Pod has restarted four times, Kubernetes is in CrashLoopBackOff for this Pod.

If our application crashes as soon as it starts,
then Kubernetes will restart the Pod after some time to avoid the crash loop from eating resources on the node.
This is all handled local to the node by the kubelet without the Job being involved at all.

Let's kill the Job and try something else...

$ kubectl delete jobs oneshot

Modify the config file again to change the restartPolicy from OnFailure to Never, and launch it with kubectl apply.

$ kubectl apply -f jobs-oneshot-failure2.yaml

If we let this run for a bit and then look at related Pods we will find something interesting.

$ kubectl get pod -l job-name=oneshot -a

NAME            READY     STATUS    RESTARTS   AGE oneshot-0wm49   0/1
Error     0          1m oneshot-6h9s2   0/1       Error     0          39s
oneshot-hkzw0   1/1       Running   0          6s oneshot-k5swz   0/1
Error     0          28s oneshot-m1rdw   0/1       Error     0          19s
oneshot-x157b   0/1       Error     0          57s

We have multiple Pods that have errored out.
With restartPolicy set to Never, Job object notices the failure and creates a replacement Pod.
If we are not careful this will create a lot of junk in our cluster, for this reason it is better to use restartPolicy: OnFailure

Cleanup with kubectl delete command

$ kubectl delete jobs oneshot

We have seen a program fail by returning a nonzero exit code, but applications can fail in other ways.

Applications can get struck and not make any forward progress, we can use liveness probes with Jobs to cover this scenario.
If the liveness probe policy determines that a Pod is dead, it will be restarted / replaced for us.

Parallelism
-----------
What if we want to start a bunch of workers together to make key generation faster?
We can use a combination of completions and parallelism parameters to get 10 runs of kuard with each run generating 10 keys,
However we don't want to swamp our cluster, so we will limit ourselves to only five Pods at a time.

job-parallel.yaml
-----------------
apiVersion: batch/v1
kind: Job
metadata:
  name: parallel
  labels:
    chapter: jobs
spec:
  parallelism: 5
  completions: 10
  template:
    metadata:
	  labels:
	    chapter: jobs
	spec:
	  containers:
	  - name: kuard
	    image: gcr.io/kuar-demo/kuard-amd64:1
		imagePullPolicy: Always
		args:
		- "--keygen-enable"
		- "--keygen-exit-on-complete"
		- "--keygen-num-to-gen=10"
	  restartPolicy: OnFailure

Launch the job with kubectl apply command.

$ kubectl apply -f job-parallel.yaml
kob "parallel" created

Now watch as the Pods come up, do their thing and exit.
New Pods are created until 10 have completed altogether.

Here we use --watch or -w flag to have kubectl stay around and list changes as the happen;

$ kubectl get pods -w

Cleanup by deleting the finished Job object

$ kubectl delete job parallel

Work Queues
-----------
Common use case for Jobs is to process work from a work queue.
In this scenario, some task creates a number of work items and publishes them to a work queue.
A worker Job can be run to process each work item until the work queue is empty.

Starting a Work Queue
---------------------
kuard has a simple memory based work queue system built in.
We will start an instance of kuard to act as a coordinator for all the work to be done.

rs-queue.yaml
-------------
apiVersion: extensions/v1beta1
kind: ReplicaSet
metadata:
  labels:
    app: work-queue
	component: queue
	chapter: jobs
  name: queue
spec:
  replicas: 1
  template:
    metadata:
	  labels:
	    app: work-queue
		component: queue
		chapter: jobs
	spec:
	  containers:
	  - name: queue
	    image: "gcr.io/kuar-demo/kuard-amd64:1"
		imagePullPolicy: Always

Run the work queue with following command

$ kubectl apply -f rs-queue.yaml

Use port forwarding to connect to the work queue daemon

$ QUEUE_POD=$(kubectl get pods -l app=work-queue,component=queue -o jsonpath='{.items[0].metadata.name}')

$ kubectl port-forward $QUEUE_POD 8080:8080
Forwarding from 127.0.0.1:8080 -> 8080
Forwarding from [::1]:8080 -> 8080

Leave this port-forwarding command running in a terminal window

Navigate to http://localhost:8080 in a browser and switch to "MemQ Server" tab to keep an eye on what is going on.

With the work queue server in place, we should expose it using a service.
This will make it easy for producers and consumers to locate the work queue via DNS

service-queue.yaml
------------------
apiVersion: v1
kind: Service
metadata:
  labels:
    app: work-queue
	component: queue
	chapter: jobs
  name: queue
spec:
  ports:
  - port: 8080
    protocol: TCP
    targetPort: 8080
  selector:
    app: work-queue
	component: queue

Create the queue service with kubectl apply command

$ kubectl apply -f service-queue.yaml
service "queue" created

Loading Up the Queue
--------------------
We will use curl to drive the work queue server API and insert a bunch of work items.
curl will communicate to work queue server through the kubectl port-forward we set up earlier.

load-queue.sh
-------------
# Create a work queue called 'keygen'
curl -X PUT localhost:8080/memq/server/queues/keygen

# Create 100 work items and load up the queue.
for i in work-item-{0..99}; do
  curl -X POST localhost:8080/memq/server/queues/keygen/enqueue -d "$i"
done

We should see 100 JSON objects output to our terminal when we run this commands

We can confirm the status of the queue by looking at the "MemQ Server" tab in the UI,
or we can query the work queue server API with curl as shown below

$ curl 127.0.0.1:8080/memq/server/stats
{
    "kind": "stats"
    "queues": [
        {
	        "depth": 100,
		    "dequeued": 0,
		    "drained": 0,
		    "enqueued": 100,
		    "name": "keygen"
	    }
    ]
}

Now we are ready to kick off a Job to consume the work queue until its empty.

Creating The Consumer Job
-------------------------
kuard is also able to act in consumer mode.
Here we set it up to draw work items from the work queue, create a key, and then exit once the queue is empty

job-consumers.yaml
------------------
apiVersion: batch/v1
kind: Job
metadata:
  labels:
    app: message-queue
	component: consumer
	chapter: jobs
  name: consumers
spec:
  parallelism: 5
  template:
    metadata:
	  labels:
	    app: message-queue
		component: consumer
		chapter: jobs
	spec:
	  containers:
	  - name: worker
	    image: "gcr.io/kuar-demo/kuard-amd64:1"
		imagePullPolicy: Always
		args:
		- "--keygen-enable"
		- "--keygen-exit-on-complete"
		- "--keygen-memq-server=htp://queue:8080/memq/server"
		- "--keygen-memq-queue=keygen"
	  restartPolicy: OnFailure

We are telling the Job to start up five Pods in parallel by setting the parallelism to 5, and the completions parameter is unset.
This will create the Job in worker pool mode, Job will start winding down once the first Pod exits with zero exit code and not start any new Pods.
This means none of the workers should exit until the work is done and they are all in the process of finishing up.

Create the consumer Job

$ kubectl apply -f job-consumers.yaml
job "consumers" created

Once the Job has been created we can view the Pods backing the Job;

$ kubectl get pods
NAME              READY     STATUS    RESTARTS   AGE
queue-43s87       1/1       Running   0          5m
consumers-6wjxc   1/1       Running   0          2m
consumers-7l5mh   1/1       Running   0          2m
consumers-hvz42   1/1       Running   0          2m
consumers-pc8hr   1/1       Running   0          2m
consumers-w20cc   1/1       Running   0          2m

Five Pods running in parallel will continue to run until the work queue is empty,
as the queue empties, the consumer Pods will exit cleanly and the consumers Job will be considered complete.

Cleaning Up
-----------
We can clean up all the stuff we created in this section using labels as shown below

$ kubectl delete rs,svc,job -l chapter=jobs

ConfigMaps and Secrets
**********************
Container images have to be as reusable as possible.
Same image should be used for development, staging, and production.

Even better if the same image is general purpose enough to be used across applications and services.

ConfigMaps are used to provide configuration information for workloads,
This can either be fine-grained information (a short string) or a composite value in the form of a file.

Secrets are similar to ConfigMaps but focused on making sensitive information available to the workload,
They can be used for things like credentials or TLS certificates.

ConfigMaps
==========
One way to think of a ConfigMap is as a Kubernetes object that defines a small filesystem.
Another way is as a set of variables that can be used when defining the environment or command line for your containers.

Key thing is that the ConfigMap is combined with Pod right before the Pod is run,
This means the container image and the Pod definition itself can be reused across many apps by just changing the ConfigMap that is used.

Creating ConfigMaps
-------------------
We can create ConfigMaps in an immediate, imperative way or we can create them from a manifest file.

Suppose we have a file on disk "my-config.txt" that we want to make available to a Pod

my-config.txt
-------------
# Sample configuration file
parameter1 = value1
parameter2 = value2

Let's create a ConfigMap with the above file, and add few literal values from the command line

$ kubectl create configmap my-config --from-file=my-config.txt \
--from-literal=extra-param=extra-value --from-literal=another-param=another-value

Declarative equivalent of the ConfigMap created by the above command is given below.

$ kubectl get configmaps my-config -o yaml

apiVersion: v1
data:
  another-param: another-value
  extra-param: extra-value
  my-config.txt: |
    # Sample configuration file
	parameter1 = value1
	parameter2 = value2
kind: ConfigMap
metadata:
  creationTimestamp: ...
  name: my-config
  namespace: default
  resourceVersion: "13556"
  selfLink: /api/v1/namespaces/default/configmaps/my-config
  uid: 3641c553-f7de-11e6-98c9-06135271a273

As we can see, ConfigMap is really just some key/value pairs stored in an object.

Using a ConfigMap
-----------------
There are three main ways to use a ConfigMap:

Filesystem:
We can mount a ConfigMap in to a Pod, a file is created for each entry based on the key name.
Contents of that file are set to the value.

Environment Variable:
ConfigMap can be used to dynamically set the value of an environment variable.

Command Line Argument:
Kubernetes supports dynamically creating the command line for a container based on ConfiMap values.

Let's create a manifest for kuard that pulls all these together.

kuard-config.yaml
-----------------
apiVersion: v1
kind: Pod
metadata:
  name: kuard-config
spec:
  containers:
    - name: test-container
	  image: gcr.io/kuar-demo/kuard-amd64:1
	  imagePullPolicy: Always
	  command:
	    - "/kuard"
		- "$(EXTRA_PARAM)"
	  env:
	    - name: ANOTHER_PARAM
		  valueFrom:
		    configMapKeyRef:
			  name: my-config
			  key: another-param
		- name: EXTRA_PARAM
		  valueFrom:
		    configMapKeyRef:
			  name: my-config
			  key: extra-param
	  volumeMounts:
	    - name: config-volume
		  mountPath: /config
  volumes:
    - name: config-volume
	  configMap:
	    name: my-config
restartPolicy: Never

For the filesystem method we created a volume inside the Pod with name config-volume,
we then defined this volume to be a ConfigMap volume and point at the ConfiMap to mount.
We have mounted the volume on kuard container at /config with a volumeMount

We used valueFrom to specify environment variables to reference the ConfigMap and the data key to use within the ConfiMap

Command line arguments build on environment varialbles, Kubernetes will perform correct substitution with $(<env-var-name>)

Let's run this Pod, and port-forward to examine how the app sees the world

$ kubectl apply -f kuard-config.yaml
$ kubectl port-forward kuard-config 8080

Navigate to http://loaclhost:8080 in a browser and click on "Server Env" tab on the left,
this will show the command line the app was launched with along with its environment

Navigate to http://loaclhost:8080 in a browser and click on "File system browser" tab on the left,
this lets us explore the file system as the application would see it.
We should see /config volume created based on our ConfigMap, Inside /config we will see some hidden files prepended with .., 
these are used to do a clean swap of new values when the ConfigMap is updated.

Secrets
=======
There are certain extra-sensitive data, which can include passwords, security tokens, or other types of private keys.

Secrets enable container images to be created without bundling sensitive data,
this allows containers to remain portable across environments

Secrets are exposed to Pods via explicit declaration in Pod manifests and the Kubernetes API.

WARNING:
As of Kubernetes version 1.6, anyone with root access on any node has access to all secrets in the cluster,
also isolation between nodes is still a work in progress.

Kubernetes 1.7 improves quite a bit, if properly configured it both encrypts stored secrets
and restricts the secrets that each individual node has access to.

Creating Secrets
----------------
Secrets are created using Kubernetes API or via kubectl command line tool.

kuard container image does not bundle a TLS certificate or key.
This allows kuard container to remain portable across environments and distributable through public Docker registries.

Let's create a secret to store a TLS key and certificate for the kuard application
that meets the storage requirements listed above.

First step in creating a secret is to obtain the raw data we want to store.

$ curl -o kuard.crt https://storage.googleapis.com/kuar-demo/kuard.crt
$ curl -o kuard.key https://storage.googleapis.com/kuar-demo/kuard.key

With kuard.crt and kuard.key files stored locally, we can create a secret named kuard-tls to store them securely.

$ kubectl create secret generic kuard-tls --from-file=kuard.crt --from-file=kuard.key

kuard-tls secret has been created with two data elements,
run the below command to get details about the secret.

$ kubectl describe secrets kuard-tls

We can consume the kuard-tls Secret from a Pod by using a secret volume.

Consuming Secrets:
------------------
Secrets can be consumed using the Kubernetes REST API by applications

However our goal is to keep applications portable,
i.e. they should run well in Kubernetes, but they should also run unmodified on other platforms

We can also access secrets using secrets volume.

Secrets Volumes
---------------
Secrets volumes are managed by kubelet and are created at Pod creation time.
Secrets are stored on tmpfs volumes(RAM disks) and are not written to disk on nodes.

Each data element of a secret is stored in a separate file under the target mount point specified in the volume mount.

kuard-tls secret contains two data elements kuard.crt and kuard.key,
mounting kuard-tls secrets volume to tls results in the following files:

/tls/cert.pem
/tls/key.pem

Below Pod manifest declares a secrets volume whihc exposes kuard-tls secret to kuard container under /tls

kuard-secret.yaml
-----------------
apiVersion: v1
kind: Pod
metadata:
  name: kuard-tls
spec:
  containers:
    - name: kuard-tls
	  image: gcr.io/kuar-demo/kuard-amd64:1
	  imagePullPolicy: Always
	  volumeMounts:
	  - name: tls-certs
	    mountPath: "/tls"
		readOnly: true
  volumes:
    - name: tls-certs
	  secret:
	    secretName: kuard-tls

Create the kuard-tls Pod using kubectl apply command

$ kubectl apply -f kuard-secret.yaml

Port-forward to the kuard-tls Pod

$ kubectl port-forward kuard-tls 8443:8443

Navigate to http://loaclhost:8443 on a browser, we should see invalid certificate warnings as this is a self-signed certificate.
Navigate to "File System Browser" tab to find the certificates on disk

Image Pull Secrets
------------------
Kubernetes supports using images stored on private registries, but access to those images require credentials.
Private images can be stored across one or more private registries.
Challenge in managing credentials for each private registry on every possible node in the cluster.

Image Pull Secrets leverage secrets API to automate the distribution of private registry credentials.
Image Pull Secrets are stored just like normal secrets but are consumed through the spec.imagePullSecrets Pod specification field.

Use kubectl to create the special kind of secret "docker-registry"

$ kubectl create secret docker-registry my-image-pull-secret \
  --docker-username=<username> --docker-password=<password> --docker-email=<email-address>

Enable access to the private repository by referencing the image pull secret in the Pod manifest as shown below

kuard-secret-ips.yaml
---------------------
apiVersion: v1
kind: Pod
metadata:
  name: kuard-tls
spec:
  containers:
    - name: kuard-tls
	  image: gcr.io/kuar-demo/kuard-amd64:1
	  imagePullPolicy: Always
	  volumeMounts:
	  - name: tls-certs
	    mountPath: "/tls"
		readOnly: true
  imagePullSecrets:
  - name: my-image-pull-secret
  volumes:
    - name: tls-certs
	  secret:
	    secretName: kuard-tls

Naming Constraints
==================
Key names of data items in a Secret or ConfiMap are defined to map to valid environment variable names.

Key names can begin with a dot (.) followed by a letter or number.
Following characters include dots(.), dashes(-), and underscores(_)
Dots can not be repeated.
Dots and underscores or dashes can not be adjacent to each other.

Examples of valid and invalid Key names for Secrets and ConfiMaps

=======================================
 Valid Key Name   |  Invalid Key Name
=======================================
 .auth_token      |  Token..properties
---------------------------------------
 Key.pem          |  auth file.json
---------------------------------------
 config_file      |  _password.txt
---------------------------------------

NOTE:
When selecting a key name consider that these keys can be exposed to Pods via a Volume mount.
Pick a name that is going to make sense when specified on a command line or in a config file.
Storing a TLS key as key.pem is more clear than tls-key when configuring applications to access secrets

ConfigMap data values are simple UTF-8 text specified directly in the manifests.
As of Kubernetes 1.6 ConfigMaps are unable to store binary data

Secret data values hold arbitrary data encoded using base64.
Use of base64 encoding makes it possible to store binary data.
Use of base64 encoding makes it difficult to manage secrets that are stored in YAML files,
as base64-encoded value must be put in the YAML

Managing ConfigMaps and Secrets
===============================

Secrets and ConfigMaps are managed through Kubernetes API using kubectl create, describe,
get, and delete commands for manipulating these objects.

Listing Secrets and ConfiMaps
-----------------------------

$ kubectl get secrets
> lists all Secrets in the current namespace

$ kubectl get configmaps
> lists all ConfigMaps in the current namespace

$ kubectl describe configmap my-config
> get more details on a single object

$ kubectl get configmap my-config -o yaml
> See the raw data of my-config ConfigMap

$ kubectl get secret kuard-tls -o yaml
> See the raw data of kuard-tls Secret

Creating Secrets and ConfigMaps
-------------------------------

We can use "kubectl create secret generic" or "kubectl create configmap" commands to create Secrets and ConfigMaps

There are a variety of ways to specify the data items that go in to the Secret or ConfigMap,
and most of these can be combined in a single command.

--from-file=<filename>
Load from file with Secret data key same as the filename

--from-file=<key>=<filename>
Load from file with Secret data key explicitly specified

--from-file=<directory>
Load all the files in the directory whose filename is an acceptable key name.

--from-literal=<key>=<value>
Use the specified key/value pair directly

Updating Secrets and ConfigMaps
-------------------------------
We can update ConfigMap or Secret and have it reflected in running programs.
Application has to be able to re-read the configuration values,
otherwise we might need to restart the application to use the updated ConfigMap or Secret

Three Ways to Update ConfigMaps or Secrets: 

Update From File
----------------
We can edit the manifest of our ConfigMap or Secret and push a new version with kubeclt replace command

$ kubeclt replace -f <filename>

We can also use kubectl apply if we previously created the resouce with kubectl apply

$ kubectl apply -f <filename>

Updating ConfigMap can be cumbersome as there is no provision in kubectl to load data from an external file.
Data must be stored direclty in the YAML manifest, The most common use case is when ConfigMap is defined as part
of a directory or list of resources and everything is created and updated together.

Recreate and Update
-------------------
If we store the inputs for our ConfigMaps or Secrets as separate files on disk,
we can use kubectl to recreate the manifest and then use the manifest to update the object.

$ kubectl create secret generic kuard-tls --from-file=kuard.crt --from-file=kuard.key \
  --dry-run -o yaml | kubectl replace -f -

Here we first create the manifest with --dry-run flag,
and use the generated manifest to replace the existing Secret with the same name kuard-tls.
This way we can update a Secret from files on disk without having to manually base64 encode the data.

In this case we can't directly create the kuard-tls Secret from file as it already exists.

Edit Current Version
--------------------
We can use kubectl edit command to edit the existing version of the ConfigMap in our editor,
we can do this with Secrets as well, however we will get base64 encoded stuff to deal with

Live Updates
------------
Once a ConfigMap or Secret is updated using the API,
it will be pushed automatically to all volumes that use that ConfigMap or Secret.

Currently there is no built-in way to signal an application when a new version of a ConfigMap is deployed.

Deployments
***********
We have seen how to package our application as a container, create a replicated set of these containers,
and use services to load balance traffic to those containers.

All this objects are used to build a single instance of our application,
they don't help us manage releasing new versions of our application.
i.e. Pods and ReplicaSets are expected to be tied to specific container images that don't change.

Deployment object is for managing release of new versions of our application.
Deployment enables us to move from one version of our application to next version.
Deployment "roll out" process is configurable, and waits for a user configurable amount of time between upgrading individual Pods.
Deployment "roll out" process also uses health checks to ensure that new version of the application is operating correctly

Mechanics of the "roll out" performed by a Deployment is controlled by Deployment controller running in the cluster.
Deployments can proceed unattended and it will still operate correctly and safely.
This makes it easy to integrate Deployments with Continuous delivery tools and services.

Previously we created a Pod with kubectl run command like below

$ kubectl run nginx --image=nginx:1.7.12

Under the hood, this was actually creating a Deployment object,
We can view this Deployment object with kubectl get command

$ kubectl get deployments nginx
NAME   DESIRED  CURRENT  UP-TO-DATE  AVAILABLE  AGE
nginx  1        1        1           1          13s

Deployment Internals
--------------------
ReplicaSets manage Pods, Deployments manage ReplicaSets

Relationship between Deployments and ReplicaSets is defined by labels and a label selector

We can see the label selector by looking at the Deployment object;

$ kubectl get deployments nginx -o jsonpath --template {.spec.selector.matchLabels}

  map[run:nginx]

We can see that the Deployment is managing a ReplicaSet with labels run=nginx,
We can us this in a label selector query to find the specific ReplicaSet as below

$ kubectl get replicasets --selector=run=nginx
NAME              DESIRED  CURRENT  READY  AGE
nginx-1128242161  1        1        1      13m

Let's see the relationship between Deployment and ReplicaSet in action..

Resize the Deployment using imperative scale command

$ kubectl scale deployments nginx --replicas=2
deployment "nginx" scaled

Now if we list the ReplicaSet again, we should see two replicas

$ kubectl get replicasets --selector=run=nginx
NAME              DESIRED  CURRENT  READY  AGE
nginx-1128242161  2        2        2      13m

Now let's try scaling the ReplicaSet;

$ kubectl scale replicasets nginx-112842161 --replicas=1
replicaset "nginx-112842161" scaled

Now get the ReplicaSet again...

$ kubectl get replicasets --selector=run=nginx
NAME              DESIRED  CURRENT  READY  AGE
nginx-1128242161  2        2        2      13m

Despite our scaling the ReplicaSet to one replica, it still has two replicas as its desired state.

Top level Deployment object is managing this ReplicaSet, When we adjust the number of replicas to one,
it no longer matches the desired state of the Deployment, Deployment corrects the replicas back to two.

Kubernetes is an online, self-healing system!

If we ever want to manage a ReplicaSet directly, we have to delete the Deployment that manages the ReplicaSet.
Remember to set --cascade flag to false, or else it we might delete the ReplicaSet and Pods as well!

Creating Deployments
====================
As a starting point, let's download the nginx Deployment in to a YAML file.

$ kubectl get deployments nginx --export -o yaml > nginx-deployment.yaml
$ kubectl replace -f nginx-deployment.yaml --save-config

If we look in the file, we will see something like this..

apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  annotations:
    deployment.kubernetes.io/revision: "1"
  labels:
    run: nginx
  name: nginx
  namespace: default
spec:
  replicas: 2
  selector:
    matchLabels:
	  run: nginx
  strategy:
    rollingUpdate:
	  maxSurge: 1
	  maxUnavailable: 1
	type: RollingUpdate
  template:
    metadata:
	  labels:
	    run: nginx
	spec:
	  containers:
	  - image: nginx:1.7.12
	    imagePullPolicy: Always
	  dnsPolicy: ClusterFirst
	  restartPolicy: Always

NOTE:
We need to run "kubectl replace --save-config"
This adds annotation so that when applying changes in the future,
kubectl will know what the last applied configuration was for smarter merging of configs.

If we always use "kubectl apply" then,
This step is only required after the first time we create a Deployment using "kubectl create -f".

Deployment spec contains a Pod template similar to ReplicaSet.
Deployment spec also contains a Strategy object as listed below.

...
  strategy:
    rollingUpdate:
	  maxSurge: 1
	  maxUnavailable: 1
	type: RollingUpdate
...

Strategy object dictates different ways in which a roll out of new software can proceed.
RollingUpdate and Recreate are the two different strategy supported by Deployment

Managing Deployments
====================

We can get detailed information about a Deployment using kubectl describe command

$ kubectl describe deployments nginx

Name:                   nginx
...
...
OldReplicaSets:         <none>
NewReplicaSet:          nginx-1128242161 (2/2 replicas created)
Events:
  FirstSeen   ...   Message
  ---------   ...   -------
  5m          ...   Scaled up replica set nginx-1128242161 to 1
  4m          ...   Scaled up replica set nginx-1128242161 to 2


Two of the important pieces of information in the output are OldReplicaSets and NewReplicaSets.
These fields point to the ReplicaSet objects this Deployment is currently managing.

If a Deployment is in the middle of a rollout, both fields will be set to a value,
OldReplicaSets will be set to <none> once the roll out is complete.

We can use "kubectl rollout history" command to obtain the history of rollouts associated with a Deployment.

Updating Deployments
====================
Two most common operations on a Deployment are scaling and application updates.

Scaling a Deployment
--------------------
We could imperatively scale a Deployment using kubectl scale command like below.

$ kubectl scale --replicas=3 deployment/nginx

Best practice is to manage our Deployments declaratively via YAML files, and use those files to update our Deployment.

To scale up a Deployment, we would edit our YAML file to increase the number of replicas...

...
spec:
  replicas: 3
...

Once we have increased the replicas count, we can update the Deployment using kubectl apply command.

$ kubectl apply -f nginx-deployment.yaml

$ kubectl get deployments nginx
NAME      DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE
nginx     3         3         3            3           4m


Updating Deployment's application
---------------------------------
We will edit the Deployment YAML file to update the container image as shown below...

...
	spec:
	  containers:
	  - image: nginx:1.9.10
	    imagePullPolicy: Always
...

We can also add an annotation to the template to record some information about the update..

...
spec:
  ...
  template:
    metadata:
	  annotations:
	    kubernetes.io/change-cause: "Update nginx to 1.9.10"
	  labels:
	    run: nginx
...

NOTE:
We add annotation to the "template" and not the Deployment itself.
Modification of change-cause will trigger a new roll out.

We can use kubectl apply to update the Deployment...

$ kubectl apply -f nginx-deployment.yaml

Updating the Deployment will trigger a rollout, we can monitor the rollout with kubectl rollout command...

$ kubectl rollout status deployments nginx
deployment nginx successfully rolled out

After the rollout, both old and new ReplicaSets are kept arround in case we want to roll back...

$ kubectl get replicasets -o wide
NAME               DESIRED   CURRENT   READY   ...   IMAGE(S)       ...
nginx-1128242161   0         0         0       ...   nginx:1.7.12   ...
nginx-1128635377   3         3         3       ...   nginx:1.9.10   ...

We can also pause and resume a rollout for some time when we are in middle of a rollout

$ kubectl rollout pause deployments nginx
deployment "nginx" paused

$ kubectl rollout resume deployments nginx

Rollout History
---------------
Kubernetes maintains a history of rollouts, which is useful in case we want to roll back to a specific version.

We can see the deployment history by running..

$ kubectl rollout history deployment nginx
deployments "nginx"
REVISION        CHANGE-CAUSE
1               <none>
2               Update nginx to 1.9.10

We can add --revision flag to view more details about a particular revision...

$ kubectl rollout history deployment nginx --revision=2

If there is an issue with the latest release, we can roll back by using kubectl rollout undo command..

$ kubectl rollout undo deployment nginx
deployment "nginx" rolled back

The undo command works regardless of the stage of the rollout.
We can undo both partially completed and fully completed rollouts.

An undo of a rollout is actually a rollout in reverse,
all of the policies that control rollout strategy apply to undo as well

CAUTION:
When we do a "kubectl rollout undo" our declarative manifest (YAML file) is not updated.
Alternate way to undo a rollout is to revert changes to our YAML file and "kubectl apply" the previous version.

Let's look at our deployment history again...

$ kubectl rollout history deployment nginx
REVISION        CHANGE-CAUSE
1               <none>
3               Update nginx to 1.10.2
4               Update nginx to 1.9.10

Revision 2 is missing in the history !!!

When we roll back to a previous version, the Deployment reuses the previous version and reorders it in to next version.

We can also roll back a Deployment to a specific version using --to-revision flag..

$ kubectl rollout undo deployments nginx --to-revision=3
deployment "nginx" rolled back

$ kubectl rollout history deployment nginx
deployments "nginx"
REVISION        CHANGE-CAUSE
1               <none>
4               Update nginx to 1.9.10
5               Update nginx to 1.10.2

Specifying revision 0 with --to-revision will roll back to previous version.

By default, complete revision history of a Deployment is kept attached to the Deployment object itself.
It is recommended that we set a maximum history size for the Development revision history

We should use the revisionHistoryLimit property in the Deployment specification to set the history size.

...
spec:
  # We do daily rollouts, limit the revision history to two weeks of releases.
  revisionHistoryLimit: 14
...

Deployment Strategies
=====================
Deployment supports two types of rollout strategies

> Recreate
> RollingUpdate

Recreate Strategy
-----------------
Recreate strategy simply updates the ReplicaSet managed by the Deployment to use the new image and
terminates all existing Pods associated with the Deployment.
The ReplicaSet notices that it no longer has any replicas and re-creates all Pods using the new image.

This strategy will result in some site downtime.

RollingUpdate Strategy
----------------------
RollingUpdate strategy works by updating a few Pods at a time,
moving incrementally until all of the Pods are running the new version of our application.


**************************************************************************************************************************
**************************************************************************************************************************
Managing Multiple Versions of Our Service
-----------------------------------------
For a period of time, both the new and old version of our service will be receiving requests and serving traffic.
It is critically important that each version of our software and all of its clients are capable of talking interchangeably
with both a slightly older and a slightly newer version of our software.

Consider the following scenario where we are in the middle of rolling out our frontend software;

> Half of our servers are running version 1, remaining half of our servers are running version 2

> A user makes an initial request which is serviced by version 1 server, he downloads a client-side JavaScript library from version 1 server.

> The client library runs in the user's browser and makes subsequent API requests to our service

> These API requests happen to be routed to version 2 server.

> Here version 1 of our JavaScript client library is talking to version 2 of our API server.

If we did not ensure compatibility between these versions, our application won't function correctly.

Note that this is not limited to JavaScript clients,
same thing is true of client libraries that are compiled into other services that make cals to our service.

This sort of Backward compatibility is critical to decoupling our service from systems that depend on our service.

If we don't formalize our APIs and decouple ourself,
we are forced to carefully manage our rollouts with all of the other systems that call into our service.

**************************************************************************************************************************
**************************************************************************************************************************

Configuring RollingUpdate Strategy
----------------------------------
There are two parameters we can use to tune the rolling update behavior.
> maxUnavailable
> maxSurge

maxUnavailable parameter sets the maximum number of Pods that can be unavailable during the rolling update.
It can either be set to an absolute number of Pods, e.g., 3 or to a percentage e.g., 20%

maxUnavailable parameter helps tune how quickly a rolling update proceeds.

Example:
If we set maxUnavailable to 50%,
1. RollingUpdate will immediately scale the old ReplicaSet down to 50% of its original size
2. RollingUpdate then scales the new ReplicaSet to 50% of the Deployment's original size
3. RollingUpdate will scale the old ReplicaSet down to zero Pods
4. RollingUpdate then scales the new ReplicaSet to 100% of the Deployment's original size

maxUnavailable set to 50% completes the roll out in just four steps, but with only 50% of service capacity at times.

maxUnavailable set to 25% will complete the roll out in eight steps with minimum 75% of service capacity at any time

maxSurge parameter controls how many extra resources can be created to achieve a rollout
Similar to maxUnavailable, maxSurge can either be specified as a number or a percentage

Example:
If we set maxUnavailable to 0 and maxSurge to 20%,
1. RollingUpdate will immediately scale the new ReplicaSet to 20% of the old ReplicaSet's original size
2. RollingUpdate will then scale down the old ReplicaSet to 80% of its original size
3. RollingUpdate will scale the new ReplicaSet by another 20% to 40% of the old ReplicaSet's original size
4. RollingUpdate will then scale down the old ReplicaSet to 60% of its original size
5. These steps are repeated until old ReplicaSet is scaled down to zero and new ReplicaSet is scaled up to 100% of original size.

At any time the capacity of the system is at least 100% and,
maximum extra resource used for the rollout are limited to an additional 20% of all resource

NOTE:
Setting maxSurge to 100% is equivalent to blue/green deployment.

NOTE:
recreate rollout strategy is actually identical to the rolling update strategy with maxUnavailable set to 100%

 
Slowing Rollouts to Ensure Service Health
-----------------------------------------
Purpose of a staged rollout is to ensure that the rollout results in a healthy, stabe service running new software version.
Deployment controller waits until a Pod's Readiness checks to pass, before moving to updating the next Pod

Sometimes Pod being ready does not give us sufficient confidence that our software is behaving correctly.
Some error conditions only occur after a period of time, we could have a memory leak that takes a few minutes to show up,
or we could have a bug that is only triggered by 1% of all requests.

In most real world scenarios we want to wait a period of time to have high confidence that the new version
is operating correctly before we move on to updating the next Pod.

We can specify this time to wait in Deployments using minReadySeconds parameter

...
spec:
  minReadySeconds: 60
...

Setting minReadySeconds to 60 indicates that the Deployment must wait for 60 seconds after seeing a Pod become healthy,
before moving on to updating the next Pod

Timeout:
--------
We can also set a time out that limits how long Deployment controller will wait for a Pod's Readiness checks to pass.

We can specify this time out period in Deployments using progressDeadlineSeconds parameter

...
spec:
  progressDeadlineSeconds: 600
...

This example sets the progress deadline to 10 minutes

Deleting Deployment
-------------------

We can delete a Deployment with imperative command kubectl delete

$ kubectl delete deployments nginx

We can also use the declarative manifest to delete the Deployment

$ kubectl delete -f nginx-deployment.yaml

In both the cases, deleting a Deployment deletes any ReplicaSets being managed by the Deployment,
as well as any Pods being managed by those ReplicaSets.

We can use the --cascade=false flag to delete only the Deployment object.

Storage Solutions and Kubernetes
********************************
Here we cover a variety of approaches for integrating storage in to containerized microservices in Kubernetes

> How to import existing external storage solutions in to Kubernetes

> How to reliably run singletons in Kubernetes that enable us to have an environment that
  largely matches the VMs we previously deployed storage solutions

> StatefulSets that represent the future of stateful workload in Kubernetes


Importing External Services
===========================

Sometimes it is needed that we should represent an external service in Kubernetes for multiple reasons,
like taking advantage of built-in naming and service discovery primitives provided by Kubernetes.

Representing external services in Kubernetes also enables us to configure all our applications,
so that it looks like the database that is running on a machine somewhere is actually a Kubernetes service.

Once we start using external database as Kubernetes service, it is easy to run the database as Kubernetes service.

Example:
In production we may rely on a legacy database that is running on a VM,
for continuous testing we may deploy a test database as a transient container without any data persistence.
Representing both the databases as Kubernetes services enables us to maintain identical configuration in testing and production.

High fidelity between test and production ensures that passing tests will lead to successful deployment in production.

Example:
Imagine that we have test and production namespaces defined, 
The test service is imported using an object like:

kind: Service
metadata:
  name: my-database
  # note 'test' namespace here
  namespace: test
...

production service looks the same, except it uses a different namespace:

kind: Service
metadata:
  name: my-database
  # note 'prod' namespace here
  namespace: prod
...

Same service name in two different namespaces resolves to tow different services.

Services Without Selectors
--------------------------
We previously discussed about labels and selectors and,
how they were used to identify the dynamic set of Pods that were the backends for a particular service.

With external services, there is no such label query.
Instead, we generally have a DNS name that points to the specific server running the database.

Example:
Let's assume that our database server is named database.company.com.
To import this external database service in to Kubernetes, we creating a service without Pod selector.
Instead, the service references the DNS name of the database server.

dns-service.yaml
----------------
kind: Service
apiVersion: v1
metadata:
  name: external-database
spec:
  type: ExternalName
  externalName: database.company.com

When a typical Kubernetes service is created, an IP address is also created and,
the Kubernetes DNS service is populated with an A record that points to that IP address.

When we create a externalName Service, Kubernetes DNS service is populated with
a CNAME record that points to the external name we specified. (database.company.com in this case)

When an application in the cluster does a DNS lookup for hostname external-database.svc.default.cluster,
DNS protocol aliases that name to 'database.company.com'. This then resolves to the IP address of our external database.

Sometimes we don't have a DNS address for an external service, we might just have an IP address.
It is still possible to import the external service as a Kubernetes Service using the below sequence of steps.

1. Create a Service without a label selector and don't specify the service type as ExternalName

external-ip-service.yaml
------------------------
kind: Service
apiVersion: v1
metadata:
  name: external-ip-database

At this point, Kubernetes will allocate a virtual IP address for this service and populate an A record for it.
However, because there is no selector for the service, there will be no endpoints populated for the load balancer to redirect traffic to.

2. Creat an Endpoints object with the IP address for the Service

external-ip-endpoints.yaml
--------------------------
kind: Endpoints
apiVersion: v1
metadata:
  name: external-ip-database
subsets:
  - addresses:
    - ip: 192.168.0.1
	ports:
	- port: 3306

If we have more than one IP address for the external service, we can repeat them in the addresses array.
Once the endpoints are populated, the load balancer will start directing traffic from Kubernetes service to the IP address endpoint(s)

NOTE:
We have to assume responsibility for keeping the IP addresses in the Endpoints object up to date.
We need to either get static IP address for the external service,
or have an automated process to update the Endpoints record when the IP address changes.

WARNING:
External services in Kubernetes do not perform any health checking.
We are responsible for ensuring that the endpoint or DNS name supplied to Kubernetes is reliable

Running Reliable Singletons
===========================
The challenge of running storage solutions in Kubernetes is that primitives like ReplicaSet expect
every container is identical and replaceable, which is not the case for most storage solutions.

One option to address this issue is to use Kubernetes primitives, but not attempt to replicate the storage.
Instead, simply run a single Pod that runs the database or other storage solution.

This might seem to run counter to principles of building reliable distributed systems,
If we structure the system properly the only thing we are sacrificing is potential downtime for upgrades or,
in case of machine failure. which is acceptable for many smaller-scale applications.

Running a MySQL Singleton
-------------------------
Run a reliable singleton instance of MySQL database as a Pod and expose the singleton to other applications in the cluster.

To do this, we are going to create three basic objects:

> A persistent volume to manage the lifespan of the on-disk storage independently from the lifespan of the running MySQL application
  
> A MySQL Pod that will run the MySQL application

> A Service that will expose this Pod to other containers in the cluster.

If the application moves to a different machine due to application crash or machine failure, Volume should move with it,
and data should be preserved. Separating the data storage out as a persistent volume makes this possible.

Create a persistent volume for our MySQL database:
--------------------------------------------------
This example uses NFS for maximum portability, Kubernetes supports many different persistent volume drive types.

nfs-volume.yaml
---------------
apiVersion: v1
kind: PersistentVolume
metadata:
  name: database
  labels:
    volume: my-volume
spec:
  accessModes:
  - ReadWriteMany
  capacity:
    storage: 1Gi
  nfs:
    server: 192.168.0.1
	path: "/exports"

This YAML file defines persistent volume object with 1 GB of storage space,
we can create this persistent volume as usual with kubectl apply command as below.

$ kubectl apply -f nfs-volume.yaml


Now that we have a persistent volume created, we need to claim that persistent volume for our Pod,
we do this with a PersistentVolumeClaim object.

nfs-volume-claim.yaml
---------------------
kind: PersistentVolumeClaim
apiVersion: v1
metadata:
  name: database
spec:
  accessModes:
  - ReadWriteMany
  resources:
    requests:
	  storage: 1Gi
  selector:
    matchLabels:
	  volume: my-volume

Here we use the selector field with label to find the matching volume we defined previously,
this kind of indirection might seem overly complicated, however it serves to isolate our Pod definition from our storage definition.

We can declare volumes directly inside a Pod specification, but that would lock the Pod specification to a particular volume provider,
e.g., a specific public or private cloud, or on-premise data center

By using volume claims we can keep our Pod specification cloud-agnostic; simply create different volumes, specific to cloud,
and use a PersistentVolumeClaim to bind them together.

Now that we have claimed our volume, we can use ReplicaSet to construct our singleton Pod.
If we create our singleton as a bare Pod, then once it is scheduled to a machine, that Pod is bound to that machine forever.
If the machine fails, then the bare Pod is lost as it is not being managed by a higher level controller like a ReplicaSet
That is why we will be using the higher level ReplicaSte controller with replica size of one.


mysql-replicaset.yaml
---------------------
apiVersion: extensions/v1beta1
kind: ReplicaSet
metadata:
  name: mysql
  # labels so that we can bind a Service to this Pod
  labels:
    app: mysql
spec:
  replicas: 1
  selector:
    matchLabels:
	  app: mysql
  template:
    metadata:
	  labels:
	    app: mysql
	spec:
	  containers:
	  - name: database
	    image: mysql
		resources:
		  requests:
		    cpu: 1
			memory: 2Gi
		env:
		# Environment variables are not a best practice for security
		# We are using them for brevity in this example
		- name: MYSQL_ROOT_PASSWORD
		  value: some-password-here
		livenessProbe:
		  tcpSocket:
		    port: 3306
		ports:
		- containerPort: 3306
		volumeMounts:
		  - name: database
		  # /var/lib/musql is where MySQL stores its databases
		  mountPath: "/var/lib/mysql"
	  volumes:
	  - name: database
	    persistentVolumeClaim:
		  claimName: database

Final step is to to expose the ReplicaSet as a Kubernetes Service.

mysql-service.yaml
------------------
apiVersion: v1
kind: Service
metadata:
  name: mysql
spec:
  ports:
  - port: 3306
    protocol: TCP
  selector:
    app: mysql

Now we have a singleton MySQL instance running and exposed as a Service names mysql.
We can access the MySQL instance using full domain name mysql.svc.default.cluster

Dynamic Volume Provisioning:
----------------------------
With dynamic volume provisioning, the cluster operator creates one or more StorageClass objects.
Here is a default storage class that automatically provisions disk objects on Azure.

storageclass.yaml
-----------------
apiVersion: storage.k8s.io/v1beta1
kind: StorageClass
metadata:
  name: default
  annotations:
    storageclass.beta.kubernetes.io/is-default-class: "true"
  labels:
    kubernetes.io/cluster-service: "true"
provisioner: kubernetes.io/azure-disk

Once a StorageClass has been created for a cluster, we can refer to this StorageClass in our PersistentVolumeClaim,
rather than referring to any specific PersistentVolume, when the dynamic provisioner sees this storage claim,
it uses the appropriate volume driver to create the volume and bind it to our PersistentVolumeClaim

Below is an example of a PersistentVolumeClaim that uses the default StorageClass we just defined to claim a newly created volume.

dynamic-volume-claim.yaml
-------------------------

apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: my-claim
  annotations:
    volume.beta.kubernetes.io/storage-class: default
spec:
  accessModes:
  - ReadWriteOnce
  resources:
    requests:
	  storage: 10Gi

The volume.beta.kubernetes.io/storage-class annotation is what links this claim to the storage class we created

Persistent volumes are great for traditional applications that require storage,
StatefulSet object has to be used if we need to develop highly available, scalable storage in a Kubernetes native fashion.

We will see how to deploy MongoDB on Kubernetes using StatefulSets

Kubernetes Native Storage with StatefulSets
===========================================
Kubernetes was developed with heavy emphasis on homogeneity of all replicas in a replicated set.
Replicas don't have an individual identity or configuration, which makes it quite difficult to develop stateful applications.

StatefulSets were introduced in to Kubernetes in version 1.5 to deal with stateful applications

Properties of StatefulSets
--------------------------
StatefulSets are replicated groups of Pods similar to ReplicaSets, but with certain unique properties listed below.

> Each replica gets a persistent hostname with a unique index (e.g., database-0, database-1, etc.)

> Each replica is created in order from lowest to highest index,
  and creation will block until the Pod at previous index is healthy and available.
  This order of creation also applies to scaling up.
  
> When deleted, each replica will be deleted in order from highest to lowest.
  This also applies to scaling down the number of replicas.
  
Manually Replicated MongoDB with StatefulSets
---------------------------------------------
We will deploy a replicated MongoDB cluster, for now replication will be done manually.

mongo-simple.yaml
-----------------
apiVersion: apps/v1bets1
kind: StatefulSet
metadata:
  name: mongo
spec:
  serviceName: "mongo"
  replicas: 3
  template:
    metadat:
	  labels:
	    app: mongo
	  spec:
	    containers:
		- name: mongodb
		  image: mongo:3.4.1
		  command:
		  - mongodb
		  - --replset
		  - rs0
		  ports:
		  - containerPort: 27017
		    name: peer

Above definition is similar to ReplicaSet definition, only changes are the apiVersion and kind fields.

$ kubectl apply -f mongo-simple.yaml

We can inspect the StatefulSet by running "kubectl get pods" command

$ kubectl get pods
NAME     READY  STATUS             RESTARTS  AGE
mongo-0  1/1    Running            0         1m
mongo-1  0/1    ContainerCreating  0         10s

Here each replicated Pod has a numeric index instead of the random suffix added by ReplicaSet controller.
Also Pods are being slowly created in order, not all at once as they would be with a ReplicaSet

Once the StatefulSet is created, we have to create a "headless" service to manage the DNS entries for the StatefulSet.

A Service is called "headless" if it doesn't have a cluster virtual IP address.
With StatefulSets each Pod has a unique identity, it doesn't make sense to have a load-balancing IP address for the replicated service.

We can create a headless Service by specifying clusterIP: None in the Service definition as below

mongo-service.yaml
------------------
apiVersion: v1
kind: Service
metadata:
  name: mongo
spec:
  ports:
  - port: 27017
    name: peer
  clusterIP: None
  selector:
    app: mongo

$ kubectl apply -f mongo-service.yaml

Once we create the service, mongo.default.svc.cluster.local is created,
doing a DNS lookup on this hostname provides all the addresses in the StatefulSet

In addition, entries are created for mongo-0.mongo.default.svc.cluster.local, mongo-1.mongo.default.svc.cluster.local,
and mongo-2.mongo.default.svc.cluster.local, each of these resolve to specific IP address of the replica index in the StatefulSet

With StatefulSets we get a well defined, persistent names for each replica in the set.
This is very useful when configuring replicated storage solution.

We can see these DNS entries in action by running commands in one of the Mongo replicas

$ kubectl run -it --rm --image busybox busybox ping mongo-1.mongo

Now that we have the StatefulSet running, we can manually set up Mongo replication as below.

mongo-0.mongo will be our initial primary.

$ kubeclt exec -it mongo-0 mongo
> rs.initiate( {
  _id: "rs0",
  members:[ {_id: 0, host: "mongo-0.mongo:27017"})]
  });
  OK
  
This command tells mongodb to initiate a ReplicaSet rs0 with mongo-0.mongo as the primary replica.

Once we have initiated the Mongo ReplicaSet, we can add the remaining replicas by running the below commands.

$ kubectl exec -it mongo-0 mongo
> rs.add("mongo-1.mongo:27017");
> rs.add("mongo-2.mongo:27017");

Here we are using the replica specific DNS names to add them as replicas to the Mongo cluster.

Automating MongoDB Cluster Creation
-----------------------------------
We are going to add an additional container to our Pods to perform the initialization,
also we are going to use ConfiMap to add script in to existing MongoDB image.

Here is the container we are adding to our StatefulSet

...
	  spec:
	    containers:
		- name: init-mongo
		  image: mongo:3.4.1
		  command:
		  - bash
		  - /config/init.sh
		  volumeMounts:
		  - name: config
		    mountPath: /config
		volumes:
		- name: config
		  configMap:
		    name: "mongo-init"

ConfiMap volume named mongo-init holds a script that performs our initialization

mongo-configmap.yaml
--------------------
apiVersion: v1
kind: ConfigMap
metadata:
  name: mongo-init
data:
  init.sh: |
    #!/bin/bash
	# Need to wait for the readiness health check to pass so that mongo names resolve.
	until ping -c 1 ${HOSTNAME}.mongo; do
	  echo "waiting for DNS (${HOSTNAME}.mongo)..."
	  sleep 2
	done
	
	until /usr/bin/mongo --eval 'printjson(db.serverStatus())'; do
	  echo "connecting to local mongo..."
	  sleep 2
	done
	echo "connected to local."
	
	HOST=mongo-0.mongo:27017
	
	until /usr/bin/mongo --host=${HOST} --eval 'printjson(db.serverStatus())'; do
	  echo "connecting to local mongo..."
	  sleep 2
	done
	echo "connected to remote."

    if [[ "${HOSTNAME}" != 'mongo-0' ]]; then
      until /usr/bin/mongo --host=${HOST} --eval="printjson(rs.status())" \
            | grep -v "no replset config has been received"; do
        echo "waiting for replication set initialization"
        sleep 2
      done
      echo "adding self to mongo-0"
      /usr/bin/mongo --host=${HOST} \
         --eval="printjson(rs.add('${HOSTNAME}.mongo'))"
    fi

    if [[ "${HOSTNAME}" == 'mongo-0' ]]; then
      echo "initializing replica set"
      /usr/bin/mongo --eval="printjson(rs.initiate(\
          {'_id': 'rs0', 'members': [{'_id': 0, \
           'host': 'mongo-0.mongo:27017'}]}))"
    fi
    echo "initialized"

    while true; do
      sleep 3600
    done

NOTE:
This script sleeps forever after initializing the cluster.
Every container in a Pod has to have the same RestartPolicy. Since we do not want our main Mongo container to be restarted,
we need have our initialization container run forever too, or else Kubernetes migh think our Mongo Pod is unhealthy.

Below is the complete StatefulSet that uses the ConfiMap to setup replicated MongoDB cluster.

mongo.yaml
----------
apiVersion: apps/v1bets1
kind: StatefulSet
metadata:
  name: mongo
spec:
  serviceName: "mongo"
  replicas: 3
  template:
    metadata:
	  labels:
	    app: mongo
	spec:
	  containers:
	  - name: mongodb
	    image: mongo:3.4.1
		command:
		- mongod
		- --replset
		- rs0
		ports:
		- containerPort: 27017
		  name: web
	  # This container initializes the mongodb server and sleeps forever.
	  - name: init-mongo
	    image: mongo:3.4.1
		command:
		- bash
		- /config/init.sh
		volumeMounts:
		- name: config
		  mountPath: /config
	  volumes:
	  - name: config
	    configMap:
		  name: "mongo-init"

Given all of these files, we can create a Mongo cluster with:

$ kubectl apply -f mongo-config-map.yaml
$ kubectl apply -f mongo-service.yaml
$ kubectl apply -f mongo.yaml

We can also combine all the definitions in to a single YAML file, with individual objects separated by ---
Ordering of the individual objects is necessary, since the StatefulSet definition relies on ConfigMap and so on.

Persistent Volumes and StatefulSets
-----------------------------------
For persistent storage we need to mount a persistent volume in to /data/db directory.
In Pod template we need to update it to mount a persistent volume claim to /data/db directory.

...
       volumeMounts:
	   - name: database
	     mountPath: /data/db

As StatefulSet replicates more than one Pod, we can't simply reference a persistent volume claim.
Instead we need to add a persistent volume claim template

We can think of persistent volume claim template as being identical to the Pod template,
but instead of creating Pods, it creates volume claims.

We have to add the below at the bottom of our StatefulSet definition.

    volumeClaimTemplate:
	- metadata:
	    name: database
		annotations:
		  volume.alpha.kubernetes.io/storage-class: anything
	  spec:
	    accessModes: [ "ReadWriteOnce" ]
		resources:
		  requests:
		    storage: 100Gi

When we add a volume claim template to a StatefulSet definition,
each time the StatefulSet controller creates a Pod it will create a persistent volume claim based on the template as part of that Pod.

NOTE:
In order for these replicated persistent volumes to work correctly,
We should either have auto-provisioning set up for persistent volumes, or we need to pre-populate a collection of persistent volume objects
for the StatefulSet controller to draw from.
If there is no claims that can be created, the StatefulSet controller will not be able to create the corresponding Pods.

One Final Thing: Liveness Probes
---------------------------------
Final piece in productionizing our MongoDB cluster is to add liveness checks to our mongo containers.
As we learned previously, liveness probe is used to determine if a container is operating correctly.

We can use the mongo tool itself by adding the following to the Pod template in the StatefulSet object.

...
 livenessProbe:
   exec:
     command:
	 - /usr/bin/mongo
	 - --eval
	 - db.serverStatus()
   initialDelaySeconds: 10
   timeoutSeconds: 10
...

Deploying Real World Applications
*********************************
We will look at deploying three real world applications on Kubernetes:

>Parse, an open source API server for mobile applications

>Ghost, a blogging and content management platforms

>Redis, a light weight performant key/value store

Parse:
======
Parse server is a cloud API dedicated to providing easy-to-use storage for mobile applications
Parse was purchased by Facebook in 2013 and subsequently shut down, fortunately a compatible open source version exists.

Prerequisites:
--------------
Parse uses MongoDB cluster for its storage, this section assumes that we have a three replica Mongo cluster
running on Kubernetes with names mongo-0.mongo, mongo-1.mongo, and mongo-2.mongo

Building the Parse Server
-------------------------
The open source parse-server comes with a Dockerfile by default...


> Clone the Parse repository:

$ git clone https://github.com/ParsePlatform/parse-server

> Navigate to parse-server directory and build the image:

$ cd parse-server
$ docker build -t ${DOCKER_USER}/parse-server

> Push the image to Docker hub

$ docker push ${DOCKER_USER}/parse-server

Deploying the Parse Server
--------------------------
Parse looks for three environment variables when being configured;

APPLICATION_ID
An identifier for authorizing our application

MASTER_KEY
An identifier that authorizes the master (root) user

DATABASE_URI
The URI for your MongoDB cluster

We can deploy Parse on Kubernetes using the below Deployment specification...

parse.yaml
----------
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: parse-server
  namespace: default
spec:
  replicas: 1
  template:
    metadata:
	  labels:
	    run: parse-server
	spec:
	  containers:
	  - name: parse-server
	    image: ${DOCKER_USER}/parse-server
		env:
		- name: DATABASE_URI
		  value: "mongodb://mongo-0.mongo:27017,\
		    mongo-1.mongo:27017,mongo-2.mongo\
			:27017/dev?replicaSet=rs0"
		- name: APP_ID
		  value: my-app-id
		- name: MASTER_KEY
          value: my-master-key

Exposing Parse Deployment
-------------------------
We have to expose our Deployment as a Service for us to be able to test it.

parse-service.yaml
------------------
apiVersion: v1
kind: Service
metadata:
  name: parse-server
  namespace: default
spec:
  ports:
  - port: 1337
    protocol: TCP
	targetPort: 1337
  selector:
    run: parse-server


Ghost:
======
Ghost is a popular blogging engine that can either use a file-based SQLite database or MySQL for storage.

Configuring Ghost
-----------------
Ghost is configured with a simple JavaScript file that describes the server, we will store this file as ConfiMap

A simple development configuration for Ghost looks like below...

ghost-config.js
---------------
var path = require('path'), config;

config = {
    development: {
	    url: 'http://localhost:2368',
		database: {
		    client: 'sqlite3',
			connection: {
			    filename: path.json(process.env.GHOST_CONTENT, '/data/ghost-dev.db')
			},
			debug: false
		}'
		server: {
		    host: '0.0.0.0',
			port: '2368'
		},
		paths: {
		    contentPath: path.join(process.env.GHOST_CONTENT, '/')
		}
	}
};

module.exports = config;

Once we have this configuration saved as ghost-config.js, we can create a ConfiMap object using the below commnad.

$ kubectl create cm --from-file ghost-config.js ghost-config

This command creates a ConfiMap named ghost-config, we can mount this configuration file as a volume inside our container.

Ghost Deployment definition with config volume mount...

ghost.yaml
----------
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: ghost
spec:
  replicas: 1
  selector:
    matchLabels:
      run: ghost
  template:
    metadata:
      labels:
        run: ghost
    spec:
      containers:
      - image: ghost
        name: ghost
        command:
        - sh
        - -c
		- cp /ghost-config/ghost-config.js /var/lib/ghost/config.js
		  && /usr/local/bin/docker-entrypoint.sh node current/index.js
		volumeMounts:
		- mountPath: /ghost-config
		  name: config
	  volumes:
	  - name: config
	    configMap:
		  defaultMode: 420
		  name: ghost-config

NOTE:
ConfiMaps can only mount directories and NOT INDIVIDUAL FILES
This is why he are copying config.js file in to /var/lib/ghost/ directory,
Ghost expects other files in that directory and we can't mount the ConfigMap in to /var/lib/ghost/ directory.

$ kubectl apply -f ghost.yaml

Once the Pod is up and running, we can expose it as a Service...

$ kubectl expose deployments ghost --port=2368

Once the Service is exposed, we can use kubectl proxy command to access the Ghost server...

$ kubectl proxy

Visit http://loaclhost:8001/api/v1/namespaces/default/services/ghost/proxy in browser to start interacting with Ghost.

NOTE:
In this case the contents of the blog are stored in a local file inside the container, which is not reliable

Ghost with MySQL
----------------
To store the blog's data in MySQL database, we should first modify the config.js to include the below section

...
database: {
   client: 'mysql',
   connection: {
     host     : 'mysql',
	 user     : 'root',
	 password : 'root',
	 database : 'ghost_db',
	 charset  : 'utf8'
   }
},
...

Create the ghost-config ConfigMap object...

$ kubectl create configmap ghost-config-mysql --from-file ghost-config.js

Update the Ghost Deployment definition to change the mounted ConfigMap name from ghost-config to ghost-config-mysql

...
     - configMap:
	     name: ghost-config-mysql
...


Deploy a MySQL server in the cluster using the instructions from previous chapter,
and we should make sure that it has a service named mysql defined as well...

We will need to create a database in MySQL database;

$ kubectl exec -it mysql-zzmlw -- mysql -u root -p
Enter password:
....
....
mysql> create database ghost_db;
....

Finally we have to perform a rollout to deploy our new configuration...

$ kubectl apply -f ghost.yaml

Because our Ghost server is now decoupled from its database,
we can scale up our Ghost server and it will continue to share the data across all replicas...

Edit ghost.yaml to set spec.replicas to 3 and run the below command...

$ kubectl apply -f ghost.yaml

Redis
=====
A reliable Redis installation contains two programs working together...
1. redis-server which implements the key/value store,
2. redis-sentinel which implements health checking and failover for a replicated Redis cluster

When Redis is deployed in a replicated manner, there is a single master server that can be used for both read and write operations
Additionally, there are other replica servers that duplicate the data written to the master and can be used for load balancing read operations.
Any of these replicas can fail over to become the master if the original master fails.

Failover in a replicated Redis cluster is performed by Redis sentinel.

Configuring Redis
-----------------
Redis needs separate configurations for the master and slave replicas, we will use ConfigMaps to configure our Redis installation.

For master, we have to create a file named master.conf as listed below...

master.conf
-----------
bind 0.0.0.0
port 6379

dir /redis-data

This configuration directs Redis to bind to all network interfaces on port 6379 and store its files in /redis-data directory.

Slave configuration is identical, but adds a slaveof directive as listed below...

slave.conf
----------
bind 0.0.0.0
port 6379

dir /redis-data

slaveof redis-0.redis 6379

We are using redis-0.redis for the name of Redis master, as we will be setting up this name using a Service and a StatefulSet.

We will also need to configure the Redis sentinel using sentinel.conf as listed below...

sentinel.conf
-------------
bind 0.0.0.0
port 2379

sentinel monitor redis redis-0.redis 6379 2
sentinel parallel-syncs redis 1
sentinel down-after-milliseconds redis 10000
sentinel failover-timeout redis 20000

We need to create a couple of wrapper scripts to use in our StatefulSet deployment.

init.sh looks at the hostname of the Pod and determines if it is master or slave,
and launches Redis with the appropriate configuration...

init.sh
-------
#!/bin/bash
if [[ ${HOSTNAME} == 'redis-0' ]]; then
  redis-server /redis-config/master.conf
else
  redis-server /redis-config/slave.conf
fi

sentinel.sh waits for redis-0.redis DNS name to become available and then launches redis-sentinel

sentinel.sh
-----------
#!/bin/bash
while ! ping -c 1 redis-0.redis; do
  echo 'Waiting for server'
  sleep 1
done

redis-sentinel /redis-config/sentinel.conf

We can package all of these files in to a ConfiMap object using a single command as below.

$ kubectl create configmap \
  --from-file=slave.conf=./slave.conf \
  --from-file=master.conf=./master.conf \
  --from-file=sentinel.conf=./sentinel.conf \
  --from-file=init.sh=./init.sh \
  --from-file=sentinel.sh=./sentinel.sh \
  redis-config

Creating Redis Service
----------------------
Here we have to create a headless Service by specifying clusterIP: None

redis-service.yaml
------------------
apiVersion: v1
kind: Service
metadata:
  name: redis
spec:
  ports:
  - port: 6379
    name: peer
  clusterIP: None
  selector:
    app: redis

$ kubectl apply -f redis-service.yaml

Here we are creating the Service even before the Pods are created,
Kubernetes will add the righ names when the Pods are created as part of our Redis StatefulSet

Deploying Redis StatefulSet
---------------------------

redis.yaml
----------
apiVersion: apps/v1beta1
kind: StatefulSet
metadata:
  name: redis
spec:
  replicas: 3
  serviceName: redis
  template:
    metadata:
	  labels:
	    app: redis
	spec:
	  containers:
	  - command: [sh, -c, source /redis-config/init.sh]
	    image: redis:3.2.7-alpine
		name: redis
		ports:
		- containerPort: 6379
		  name: redis
		volumeMounts:
		- mountPath: /redis-config
		  name: config
		- mountPath: /redis-data
		  name: data
	  - command: [sh, -c, source /redis-config/sentinel.sh]
	    image: redis:3.2.7-alpine
		name: sentinel
		volumeMounts:
		- mountPath: /redis-config
		  name: config
	  volumes:
	  - configMap:
	      defaultMode: 420
		  name: redis-config
		name: config
	  - emptyDir:
	    name: data

Here we have two containers in the Pod,
One runs the init.sh script and maintains the Redis server, and the other container is sentinel that monitors the servers.

Also we have two volumes defined in the Pod,
One volume is our ConfigMap to configure the Redis server and Sentinel server
Second emptyDir volume is mapped in to Redis server container to hold the application data so that it survives a container restart.

For a more reliable Redis installation, the data volume could be a network attached disk as discussed before...

$ kubectl apply -f redis.yaml

Playing with Our Redis Cluster
------------------------------
First we can determine which server the Redis sentinel belives is the master by running redis-cli command in one of the Pods.

$ kubectl exec redis-2 -c redis -- redis-cli -p 26379 sentinel get-master-addr-by-name redis

This should print out the IP address of the redis-o Pod, we can confirm this using kubectl get pods -o wide command.


Next we can confirm that the replication is working by writing data and reading back from different replicas..

Try to read the value of foo from one of the replicas:

$ kubectl exec redis-2 -c redis -- redis-cli -p 6379 get foo

We should not see any data in the response...

Try to write foo to a replica:

$ kubectl exec redis-2 -c redis -- redis-cli -p 6379 set foo 10
READONLY You can't write against a read only slave.

Let's try to write foo in to redis-0, which is the master:

$ kubectl exec redis-0 -c redis -- redis-cli -p 6379 set foo 10
OK

Now, let's try to read foo from a replica:

$ kubectl exec redis-2 -c redis -- redis-cli -p 6379 get foo
10

This shows that our Redis cluster is set up correctly and data is replicating between master and slaves.
